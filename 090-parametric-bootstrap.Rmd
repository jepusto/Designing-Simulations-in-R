
# The Parametric bootstrap

An inference procedure very much connected to simulation studies is the parametric bootstrap.
Here the core idea is to fit a given model to actual data, and then take the parameters we estimate from that model as the DGP parameters in a simulation study.
 
  The parametric bootstrap is then a simulation study for this specific scenario. In particular we do the following:
 
 1.   generate data from a model
 2.   repeatedly estimate our target quantity on a series of synthetic data sets, all generated from this model.
 3.   examine this collection of estimates to assess the character of the estimates themselves, i.e. how much they vary, whether we are        
 4.   systematically estimating too high or too low, and so forth.
 5.   The variance and bias of our estimates in our simulation is probably like the actual variance and bias of our original estimate (this is precisely the bootstrap analogy).

A key feature of the parametric bootstrap is it is not, generally, a multifactor simulation experiment.
We fit our model to the data, and use our best estimate of the world, as given by the fit model, to generate our data.
This means we generally want to simulate in contexts that are (mostly) _pivotal_, meaning the distribution of our test statistic or point estimate is relatively stable across different scenarios.

Often, to achive a reasonable claim of being pivotal, we will focus on standardized statistics, such as the $t$-statistic of

$$ t = \frac{est}{\widehat{SE}} $$
It is more common for the distribution of a standardized test statistic to have a canonical distribution across scenarios than an absolute estimate.


