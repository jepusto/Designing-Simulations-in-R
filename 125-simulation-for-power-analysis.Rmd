# Using simulation as a power calculator

We can simulate as a power calculator.
In particular, we generate data according to our best guess as to what we might find in a planned evaluation, and then analyze these synthetic data.
Do this repeatidly, and we can estimate the power we have, if we are generally right about our guesses.
This is all a power analysis is.

This has benefits over using power calculators since we can take into account odd aspects of our modeling, and also do non-standard approaches to evaluation that we might not find in a normal powe calculator.

In this example, we are planning a school-level intervention to reduce rates of discipline via a socio-emotional targeting intervention on both teachers and students, where we have strongly predictive historic data and a time-series component.


## Getting design parameters from pilot data

We had pilot data from school administrative records, and we use those to estimate parameters to plug into our simulation.
We assume our experimental sample will be on schools that have chronic issues
with discipline, so we filter on historic data to get schools we imagine are likely to be in our study.


```
library( tidyverse )
library( readxl )

datW = read_excel( "discipline_data.xlsx" )

lpd_mns = apply( datW[,-1], 2, mean )
lpd_mns

lpd_cov = cov( datW[,-1] )
lpd_cov



make_dat_param = function( n_c, n_t, tx=1 ) {
    
    n = n_c + n_t
    
    lpdisc = MASS::mvrnorm( n, mu = lpd_mns, Sigma = lpd_cov )
    colnames( lpdisc ) = paste0( "log_pdisc_", colnames( lpdisc ) )
    lpdisc = as.data.frame( lpdisc ) %>%
        mutate( ID = 1:n(),
                Z = 0 + ( sample( n ) <= n_t ) )
    
    lpdisc = lpdisc %>%
        mutate( across( log_pdisc_2015:log_pdisc_2019,
                        ~ exp( .x ) ) )
    
    names( lpdisc ) = str_replace( names(lpdisc), "log_", "" )
    
  
    lpdisc = mutate( lpdisc, 
                       pdisc_2018 = pdisc_2018 * ifelse( Z == 1, tx, 1 ),
                     pdisc_2019 = pdisc_2019 * ifelse( Z == 1, tx, 1 ) )
 
    lpdisc
}


if ( FALSE ) {
    
    a = make_dat_param( 4, 4, 0.5 )  
    aL = a %>% 
        pivot_longer( pdisc_2015:pdisc_2019, 
                      names_to = c( ".value", "year" ),
                      names_pattern = "(.*)_(.*)" ) %>%
        mutate( year = as.numeric( year ) )
    aL
    ggplot( aL, aes( year, pdisc, col=Z, group=ID ) ) +
        geom_line()
    
    aLg = aL %>% group_by( year, Z ) %>%
        summarise( pdisc = mean( pdisc ) )
    ggplot( aLg, aes( year, pdisc, col=Z, group=Z ) ) +
        geom_line()
    
}
```



```

# Parameter power simulation for cluster RCT with school-level outcomes.

library( tidyverse )

source( "make_param_data_generator.R" )





if ( FALSE ) {
    sdat = make_dat_param( 4, 4, 0.5 )
    sdat
    sdatL = pivot_longer( sdat, cols = pdisc_2015:pdisc_2018, 
                          names_to = "year",
                          values_to = "pdisc" )
    sdatL
    ggplot( sdatL, aes( year, pdisc, col=Z, group=ID ) ) +
        geom_line()
}



eval_dat = function( sdat ) {
    
    # Simple average change model
    M = lm( pdisc_2018 ~ 1 + Z + pdisc_2017 + pdisc_2016 + pdisc_2015, data=sdat )
    
    #Ml1 = lm( pdisc_2018 ~ 1 + Z + pdisc_2017, data=sdat )
    
    # No covariate adjustment average change model (on log outcome)
    M2 = lm( log( pdisc_2018 ) ~ 1 + Z, data=sdat )

    # Simple model on logged outcome
    Mrat = lm( log( pdisc_2018 ) ~ 1 + Z + log( pdisc_2017) + log( pdisc_2016) + log( pdisc_2015 ),
               data=sdat )
    
    # Look at change of disc vs average prior as outcome
    sdat = mutate( sdat,
                   avg_disc = (pdisc_2018 + pdisc_2019)/2,
                   prior_disc = (pdisc_2017 + pdisc_2016 + pdisc_2015 )/3,
                   disc = pdisc_2018 / prior_disc )
    Mrat2 = lm( disc ~ 1 + Z, data = sdat )
    
    
    # Two post-tx time periods averaged to reduce noise
    twopost = lm( log( avg_disc ) ~ 1 + Z + log( pdisc_2017 ) + log( pdisc_2016 ) + log( pdisc_2015 ), data=sdat )

    # Time fixed effects
    sdatL = pivot_longer( sdat, cols = pdisc_2015:pdisc_2019, 
                          names_to = "year",
                          values_to = "pdisc" ) %>%
        mutate( Z = Z * (year %in% c( "pdisc_2018", "pdisc_2019" ) ),
                ID = paste0( "S", ID ) )
    
    Mfe = lm( log( pdisc ) ~ 0 + ID + year + Z, 
              data=filter( sdatL, year != "pdisc_2019" ) )
    
    
    # Time fixed effects, two post
    Mfe2 = lm( log( pdisc ) ~ 0 + ID + year + Z, data=sdatL )
        
    
    
    rs = map_df( list( raw=M2, simple=M, ratio=Mrat, ratio2 = Mrat2, 
                       twopost = twopost, FE = Mfe, FE_twopost = Mfe2 ), 
                 broom::tidy, .id="model" ) %>%
        filter( term=="Z" ) %>%
        dplyr::select( -term )
    
  
    
    rs
}

# 
# eval_dat_oracle( sdat, tx ) {
#     # Oracle (single post)
#     dd = sdat %>% 
#         mutate( pdisc_2018 = pdisc_2018 * ifelse( Z, 1/tx, 1 ) ) %>%
#         dplyr::select( -Z )
#     orc = bind_rows( `1` = dd, `0` = dd, .id="Z" ) %>%
#         mutate( Z = as.numeric( Z ),
#                 pdisc_2018 = pdisc_2018 * ifelse( Z, tx, 1 ) )
#     Morc = lm( log( pdisc_2018 ) ~ 1 + Z, data=orc )
#     
#     
# }

if ( FALSE ) {
    eval_dat( make_dat_param( n_c = 4, n_t = 4, tx = 0.5 ) )
}


sim_run = function( n_c, n_t, tx, R, seed = NULL ) {
    if ( !is.null( seed ) ) {
        set.seed(seed)
    }
    cat( "Running n_c, n_t =", n_c, n_t, "tx =", tx, "\n" )
    rps = rerun( R, {
        sdat = make_dat_param(n_c = n_c, n_t = n_t, tx = tx)
        eval_dat( sdat )
    })
    bind_rows( rps )
}


if ( FALSE ) {
    sim_run( n_c = 4, n_t = 4, tx = 0.5, R = 10 )
}


#### Run the simulation #####



parallel::detectCores()

library(future)
library(furrr)

#plan(multiprocess) # choose an appropriate plan from future package
#plan(multicore)
plan(multisession, workers = parallel::detectCores() - 1 )



res = expand_grid( tx = c( 1, 0.75, 0.5 ),
                   n_c = c( 4, 5, 6, 8, 12, 20 ),
                   n_t = c( 4, 5, 6 ) )
res$R = 1000
res$seed = 1010203 + 1:nrow(res)

##
## Do the run! 
##

tictoc::tic()

# parallel version
res$res <- future_pmap(res, .f = sim_run,
                          .options = furrr_options(seed = NULL),
                          .progress = TRUE )

# non-parallel version
#res$res = pmap( res, sim_run )

tictoc::toc()




res
res = unnest( res, cols=res )

res

saveRDS( res, file="simulation_results.rds" )

res = readRDS( file="simulation_results.rds" )

sres <- res %>% group_by( n_c, n_t, tx, model ) %>%
    summarise( E_est = mean( estimate ),
               SE = sd( estimate ),
               E_SE_hat = mean( std.error ),
               pow = mean( p.value <= 0.10 ) ) # one-sided testing
sres




##### Validity ######
# Checking for validity (reject the null).  This shows the FE method is overly
# aggressive.
filter( sres, tx == 1 ) %>%
    mutate( n = n_c + n_t ) %>%
    group_by( model, n ) %>%
    summarise( pow = round( mean( pow ), digits=2 ) ) %>%
    pivot_wider( names_from=n, values_from=pow ) 


fes = filter( res, model == "FE", tx == 1, n_c < 10 )
fes
qplot( fes$p.value )
mean( fes$p.value <= 0.10 )
mean( fes$p.value <= 0.062 )


# Adjust power
res = mutate( res, threshold = ifelse( model == "FE" | model == "FE_twopost", 0.062, 0.10 ) )

sres <- res %>% group_by( n_c, n_t, tx, model ) %>%
  summarise( E_est = mean( estimate ),
             SE = sd( estimate ),
             E_SE_hat = mean( std.error ),
             pow = mean( p.value <= threshold ) ) # one-sided testing
sres



##### Precision (SE) ######


#sres = mutate( sres, 
#               MDES = 2.8*SE )

# Which methods are the most precise?

sres %>% filter( !( model %in% c("ratio2","simple") ) ) %>%
  ggplot( aes( n_c, SE, col=model )) +
    facet_grid( n_t ~ tx ) +
    geom_line() + geom_point() +
    geom_hline( yintercept = 0 )

sres

ggplot( sres, aes( tx, SE, col=model )) +
    facet_grid( n_t ~ n_c ) +
    geom_line() + geom_point() +
    geom_hline( yintercept = 0 )


##### Power ######

# Look at power over our explored contexts.  What reaches 80% power?
sres
ggplot( sres, aes( n_c, pow, col=model )) +
    facet_grid( n_t ~ tx, labeller = label_both ) +
    geom_line() + geom_point() +
    geom_hline( yintercept = 0, col="grey" ) +
    geom_hline( yintercept = c( 0.10, 0.80 ), lty=2 ) +
  theme_minimal()+ theme( legend.position="bottom",Â 
                          legend.direction="horizontal", legend.key.width=unit(1,"cm"),
                          panel.border = element_blank() ) +
  labs( title="Power for various methods vs number of controls.",
        caption="Each row corresponds to 4, 5, or 6 treated schools\n80% power marked as dashed line.", 
      y = "Power" )
ggsave(filename="power_plot.pdf", width=5, height = 7)


# Focus on the 6 6 version
s66 = filter( sres, n_c == 6, n_t == 6, tx == 0.5 )
s66
s66 = mutate( s66, 
              E_est = exp( E_est ),
              MDES = exp( - (1.64 + 0.8) * SE ),
              MDES_2 = exp( -(1.64 + 0.8) * E_SE_hat ) )
s66


# MDES for select ratio estimators

# Calculate SEs
sres2 = sres %>% group_by( model, n_c, n_t ) %>%
    summarise( SE = mean( SE ),
               E_SE_hat = mean( E_SE_hat ) ) %>%
    mutate(               MDES = 1 - exp( - (1.64 + 0.8) * SE ),
                          MDES_2 = 1 - exp( -(1.64 + 0.8) * E_SE_hat ) )
sres2

sres2 %>% filter( !(model %in% c( "oracle", "simple", "ratio2" ) ) ) %>%
  ggplot( aes( n_c, MDES, col=model ) ) +
  facet_wrap( ~ n_t, labeller = label_both ) +
  geom_point() + geom_line()  +
  #    geom_line( aes( y=MDES_2 ), lty=2, alpha=0.5 ) +
  theme_minimal() +
  theme( legend.position="bottom",
         legend.direction="horizontal", legend.key.width=unit(1,"cm"),
         panel.border = element_blank() ) +
  labs( x = "Number of control units", y = "MDES (proportion reduction of rate)",
        caption = "A MDES of 0.6 means a 60% reduction (more than half) in discipline rates",
        title = "MDES vs number of control units for various methods" )
ggsave( filename = "MDES_plot.pdf", width = 6, height = 4 )
```


