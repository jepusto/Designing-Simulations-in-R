<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Performance criteria | Designing Monte Carlo Simulations in R</title>
  <meta name="description" content="A text on designing, implementing, and reporting on Monte Carlo simulation studies" />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Performance criteria | Designing Monte Carlo Simulations in R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A text on designing, implementing, and reporting on Monte Carlo simulation studies" />
  <meta name="github-repo" content="jepusto/Designing-Simulations-in-R" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Performance criteria | Designing Monte Carlo Simulations in R" />
  
  <meta name="twitter:description" content="A text on designing, implementing, and reporting on Monte Carlo simulation studies" />
  

<meta name="author" content="James E. Pustejovsky and Luke W. Miratrix" />


<meta name="date" content="2022-05-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimation-procedures.html"/>
<link rel="next" href="case_Cronbach.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Designing Simulations in R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#some-of-simulations-many-uses"><i class="fa fa-check"></i><b>1.1</b> Some of simulation’s many uses</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#comparing-statistical-approaches"><i class="fa fa-check"></i><b>1.1.1</b> Comparing statistical approaches</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#assessing-performance-of-complex-pipelines"><i class="fa fa-check"></i><b>1.1.2</b> Assessing performance of complex pipelines</a></li>
<li class="chapter" data-level="1.1.3" data-path="index.html"><a href="index.html#assessing-performance-under-misspecification"><i class="fa fa-check"></i><b>1.1.3</b> Assessing performance under misspecification</a></li>
<li class="chapter" data-level="1.1.4" data-path="index.html"><a href="index.html#assessing-the-finite-sample-performance-of-a-statistical-approach"><i class="fa fa-check"></i><b>1.1.4</b> Assessing the finite sample performance of a statistical approach</a></li>
<li class="chapter" data-level="1.1.5" data-path="index.html"><a href="index.html#conducting-power-analyses"><i class="fa fa-check"></i><b>1.1.5</b> Conducting Power Analyses</a></li>
<li class="chapter" data-level="1.1.6" data-path="index.html"><a href="index.html#simulating-processess"><i class="fa fa-check"></i><b>1.1.6</b> Simulating processess</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#the-perils-of-simulation-as-evidence"><i class="fa fa-check"></i><b>1.2</b> The perils of simulation as evidence</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#why-r-and-rstudio"><i class="fa fa-check"></i><b>1.3</b> Why R and RStudio?</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#functions"><i class="fa fa-check"></i><b>1.3.1</b> Functions</a></li>
<li class="chapter" data-level="1.3.2" data-path="index.html"><a href="index.html#a-dangerous-function"><i class="fa fa-check"></i><b>1.3.2</b> A dangerous function</a></li>
<li class="chapter" data-level="1.3.3" data-path="index.html"><a href="index.html#function-skeletons"><i class="fa fa-check"></i><b>1.3.3</b> Function skeletons</a></li>
<li class="chapter" data-level="1.3.4" data-path="index.html"><a href="index.html#pipe-dreams"><i class="fa fa-check"></i><b>1.3.4</b> <code>%&gt;%</code> (Pipe) dreams</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="an-initial-simulation.html"><a href="an-initial-simulation.html"><i class="fa fa-check"></i><b>2</b> An initial simulation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="an-initial-simulation.html"><a href="an-initial-simulation.html#simulation-for-a-single-scenario"><i class="fa fa-check"></i><b>2.1</b> Simulation for a single scenario</a></li>
<li class="chapter" data-level="2.2" data-path="an-initial-simulation.html"><a href="an-initial-simulation.html#simulating-across-different-scenarios"><i class="fa fa-check"></i><b>2.2</b> Simulating across different scenarios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html"><i class="fa fa-check"></i><b>3</b> Structure of a simulation study</a>
<ul>
<li class="chapter" data-level="3.1" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html#general-structure-of-a-simulation"><i class="fa fa-check"></i><b>3.1</b> General structure of a simulation</a></li>
<li class="chapter" data-level="3.2" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html#tidy-simulations"><i class="fa fa-check"></i><b>3.2</b> Tidy simulations</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html#data-generating-model"><i class="fa fa-check"></i><b>3.2.1</b> Data-generating model</a></li>
<li class="chapter" data-level="3.2.2" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html#estimation-methods"><i class="fa fa-check"></i><b>3.2.2</b> Estimation methods</a></li>
<li class="chapter" data-level="3.2.3" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html#repetition"><i class="fa fa-check"></i><b>3.2.3</b> Repetition</a></li>
<li class="chapter" data-level="3.2.4" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html#performance-summaries"><i class="fa fa-check"></i><b>3.2.4</b> Performance summaries</a></li>
<li class="chapter" data-level="3.2.5" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html#results"><i class="fa fa-check"></i><b>3.2.5</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html#multiple-scenarios"><i class="fa fa-check"></i><b>3.3</b> Multiple Scenarios</a></li>
<li class="chapter" data-level="3.4" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html#keeping-the-pieces-organized"><i class="fa fa-check"></i><b>3.4</b> Keeping the pieces organized</a></li>
<li class="chapter" data-level="3.5" data-path="structure-of-a-simulation-study.html"><a href="structure-of-a-simulation-study.html#further-readings-resources"><i class="fa fa-check"></i><b>3.5</b> Further readings &amp; resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="case_ANOVA.html"><a href="case_ANOVA.html"><i class="fa fa-check"></i><b>4</b> Case Study: Heteroskedastic ANOVA</a>
<ul>
<li class="chapter" data-level="4.1" data-path="case_ANOVA.html"><a href="case_ANOVA.html#the-data-generating-model"><i class="fa fa-check"></i><b>4.1</b> The data-generating model</a></li>
<li class="chapter" data-level="4.2" data-path="case_ANOVA.html"><a href="case_ANOVA.html#the-estimation-procedures"><i class="fa fa-check"></i><b>4.2</b> The estimation procedures</a></li>
<li class="chapter" data-level="4.3" data-path="case_ANOVA.html"><a href="case_ANOVA.html#replication"><i class="fa fa-check"></i><b>4.3</b> Replication</a></li>
<li class="chapter" data-level="4.4" data-path="case_ANOVA.html"><a href="case_ANOVA.html#calculating-rejection-rates"><i class="fa fa-check"></i><b>4.4</b> Calculating rejection rates</a></li>
<li class="chapter" data-level="4.5" data-path="case_ANOVA.html"><a href="case_ANOVA.html#exAnovaExercises"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="data-generating-models.html"><a href="data-generating-models.html"><i class="fa fa-check"></i><b>5</b> Data-generating models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="data-generating-models.html"><a href="data-generating-models.html#computational-efficiency-versus-simplicity"><i class="fa fa-check"></i><b>5.1</b> Computational efficiency versus simplicity</a></li>
<li class="chapter" data-level="5.2" data-path="data-generating-models.html"><a href="data-generating-models.html#checking-the-data-generating-function"><i class="fa fa-check"></i><b>5.2</b> Checking the data-generating function</a></li>
<li class="chapter" data-level="5.3" data-path="data-generating-models.html"><a href="data-generating-models.html#exercises"><i class="fa fa-check"></i><b>5.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="data-generating-models.html"><a href="data-generating-models.html#shifted-and-scaled-t-distribution"><i class="fa fa-check"></i><b>5.3.1</b> Shifted-and-scaled t distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="estimation-procedures.html"><a href="estimation-procedures.html"><i class="fa fa-check"></i><b>6</b> Estimation procedures</a>
<ul>
<li class="chapter" data-level="6.1" data-path="estimation-procedures.html"><a href="estimation-procedures.html#further-notes-on-computational-efficiency"><i class="fa fa-check"></i><b>6.1</b> Further notes on computational efficiency</a></li>
<li class="chapter" data-level="6.2" data-path="estimation-procedures.html"><a href="estimation-procedures.html#checking-the-estimation-function"><i class="fa fa-check"></i><b>6.2</b> Checking the estimation function</a></li>
<li class="chapter" data-level="6.3" data-path="estimation-procedures.html"><a href="estimation-procedures.html#exercises-1"><i class="fa fa-check"></i><b>6.3</b> Exercises</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="estimation-procedures.html"><a href="estimation-procedures.html#adding-the-bff-test"><i class="fa fa-check"></i><b>6.3.1</b> Adding the BFF* test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="performance-criteria.html"><a href="performance-criteria.html"><i class="fa fa-check"></i><b>7</b> Performance criteria</a>
<ul>
<li class="chapter" data-level="7.1" data-path="performance-criteria.html"><a href="performance-criteria.html#inference-vs.-estimation"><i class="fa fa-check"></i><b>7.1</b> Inference vs. Estimation</a></li>
<li class="chapter" data-level="7.2" data-path="performance-criteria.html"><a href="performance-criteria.html#evaluation-of-estimation-methods"><i class="fa fa-check"></i><b>7.2</b> Evaluation of Estimation Methods</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="performance-criteria.html"><a href="performance-criteria.html#assessing-actual-properties"><i class="fa fa-check"></i><b>7.2.1</b> Assessing actual properties</a></li>
<li class="chapter" data-level="7.2.2" data-path="performance-criteria.html"><a href="performance-criteria.html#assessing-estimated-properties"><i class="fa fa-check"></i><b>7.2.2</b> Assessing estimated properties</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="performance-criteria.html"><a href="performance-criteria.html#assessing-a-point-estimator"><i class="fa fa-check"></i><b>7.3</b> Assessing a point estimator</a></li>
<li class="chapter" data-level="7.4" data-path="performance-criteria.html"><a href="performance-criteria.html#assessing-a-standard-error-estimator"><i class="fa fa-check"></i><b>7.4</b> Assessing a standard error estimator</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="performance-criteria.html"><a href="performance-criteria.html#why-not-assess-widehatse-directly"><i class="fa fa-check"></i><b>7.4.1</b> Why not assess <span class="math inline">\(widehat{SE}\)</span> directly?</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="performance-criteria.html"><a href="performance-criteria.html#assessing-a-hypothesis-testing-procedure"><i class="fa fa-check"></i><b>7.5</b> Assessing a hypothesis testing procedure</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="performance-criteria.html"><a href="performance-criteria.html#validity"><i class="fa fa-check"></i><b>7.5.1</b> Validity</a></li>
<li class="chapter" data-level="7.5.2" data-path="performance-criteria.html"><a href="performance-criteria.html#power"><i class="fa fa-check"></i><b>7.5.2</b> Power</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="performance-criteria.html"><a href="performance-criteria.html#assessing-confidence-intervals"><i class="fa fa-check"></i><b>7.6</b> Assessing confidence intervals</a></li>
<li class="chapter" data-level="7.7" data-path="performance-criteria.html"><a href="performance-criteria.html#uncertainty-in-our-performance-estimates-the-mcse"><i class="fa fa-check"></i><b>7.7</b> Uncertainty in our performance estimates (the MCSE)</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="performance-criteria.html"><a href="performance-criteria.html#mcse-for-variance-estimators"><i class="fa fa-check"></i><b>7.7.1</b> MCSE for variance estimators</a></li>
<li class="chapter" data-level="7.7.2" data-path="performance-criteria.html"><a href="performance-criteria.html#the-simhelpers-package-and-mcses"><i class="fa fa-check"></i><b>7.7.2</b> The simhelpers package and MCSEs</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="performance-criteria.html"><a href="performance-criteria.html#absolute-vs.-relative-performance-measures"><i class="fa fa-check"></i><b>7.8</b> Absolute vs. relative performance measures</a></li>
<li class="chapter" data-level="7.9" data-path="performance-criteria.html"><a href="performance-criteria.html#exercises-simulating-cronbachs-alpha"><i class="fa fa-check"></i><b>7.9</b> Exercises: Simulating Cronbach’s alpha</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="performance-criteria.html"><a href="performance-criteria.html#the-data-generating-function"><i class="fa fa-check"></i><b>7.9.1</b> The data-generating function</a></li>
<li class="chapter" data-level="7.9.2" data-path="performance-criteria.html"><a href="performance-criteria.html#the-estimation-function"><i class="fa fa-check"></i><b>7.9.2</b> The estimation function</a></li>
<li class="chapter" data-level="7.9.3" data-path="performance-criteria.html"><a href="performance-criteria.html#replicates"><i class="fa fa-check"></i><b>7.9.3</b> Replicates</a></li>
<li class="chapter" data-level="7.9.4" data-path="performance-criteria.html"><a href="performance-criteria.html#estimator-performance"><i class="fa fa-check"></i><b>7.9.4</b> Estimator performance</a></li>
<li class="chapter" data-level="7.9.5" data-path="performance-criteria.html"><a href="performance-criteria.html#confidence-interval-coverage"><i class="fa fa-check"></i><b>7.9.5</b> Confidence interval coverage</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="case_Cronbach.html"><a href="case_Cronbach.html"><i class="fa fa-check"></i><b>8</b> Case study: Cronbach Alpha</a>
<ul>
<li class="chapter" data-level="8.1" data-path="case_Cronbach.html"><a href="case_Cronbach.html#data-generating-model-1"><i class="fa fa-check"></i><b>8.1</b> Data-generating model</a></li>
<li class="chapter" data-level="8.2" data-path="case_Cronbach.html"><a href="case_Cronbach.html#estimation-procedures-1"><i class="fa fa-check"></i><b>8.2</b> Estimation procedures</a></li>
<li class="chapter" data-level="8.3" data-path="case_Cronbach.html"><a href="case_Cronbach.html#performance-calculations"><i class="fa fa-check"></i><b>8.3</b> Performance calculations</a></li>
<li class="chapter" data-level="8.4" data-path="case_Cronbach.html"><a href="case_Cronbach.html#simulation-driver"><i class="fa fa-check"></i><b>8.4</b> Simulation driver</a></li>
<li class="chapter" data-level="8.5" data-path="case_Cronbach.html"><a href="case_Cronbach.html#running-the-simulation"><i class="fa fa-check"></i><b>8.5</b> Running the simulation</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ensuring-reproducibility.html"><a href="ensuring-reproducibility.html"><i class="fa fa-check"></i><b>9</b> Ensuring reproducibility</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ensuring-reproducibility.html"><a href="ensuring-reproducibility.html#seeds-and-pseudo-random-number-generators"><i class="fa fa-check"></i><b>9.1</b> Seeds and pseudo-random number generators</a></li>
<li class="chapter" data-level="9.2" data-path="ensuring-reproducibility.html"><a href="ensuring-reproducibility.html#including-seed-in-our-simulation-driver"><i class="fa fa-check"></i><b>9.2</b> Including seed in our simulation driver</a></li>
<li class="chapter" data-level="9.3" data-path="ensuring-reproducibility.html"><a href="ensuring-reproducibility.html#reasons-for-setting-the-seed"><i class="fa fa-check"></i><b>9.3</b> Reasons for setting the seed</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="index.html"><a href="index.html#functions"><i class="fa fa-check"></i><b>10</b> More on functions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="functions.html"><a href="functions.html"><i class="fa fa-check"></i><b>10.1</b> Default arguments for functions</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="case_cluster.html"><a href="case_cluster.html"><i class="fa fa-check"></i><b>11</b> Case study: A simulation with clustered data</a>
<ul>
<li class="chapter" data-level="11.1" data-path="case_cluster.html"><a href="case_cluster.html#a-design-decision-what-do-we-want-to-manipulate"><i class="fa fa-check"></i><b>11.1</b> A design decision: What do we want to manipulate?</a></li>
<li class="chapter" data-level="11.2" data-path="case_cluster.html"><a href="case_cluster.html#a-mathematical-model-for-cluster-randomized-data"><i class="fa fa-check"></i><b>11.2</b> A mathematical model for cluster-randomized data</a></li>
<li class="chapter" data-level="11.3" data-path="case_cluster.html"><a href="case_cluster.html#multilevel-data-generation-is-a-recipe-using-a-statistical-model"><i class="fa fa-check"></i><b>11.3</b> Multilevel data generation is a recipe using a statistical model</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="case_cluster.html"><a href="case_cluster.html#generating-the-multisite-data"><i class="fa fa-check"></i><b>11.3.1</b> Generating the multisite data</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="case_cluster.html"><a href="case_cluster.html#analyzing-our-data"><i class="fa fa-check"></i><b>11.4</b> Analyzing our data</a></li>
<li class="chapter" data-level="11.5" data-path="case_cluster.html"><a href="case_cluster.html#the-simulation"><i class="fa fa-check"></i><b>11.5</b> The simulation</a></li>
<li class="chapter" data-level="11.6" data-path="case_cluster.html"><a href="case_cluster.html#analysis-of-our-single-scenario"><i class="fa fa-check"></i><b>11.6</b> Analysis of our single scenario</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="case_cluster.html"><a href="case_cluster.html#are-the-estimators-biased"><i class="fa fa-check"></i><b>11.6.1</b> Are the estimators biased?</a></li>
<li class="chapter" data-level="11.6.2" data-path="case_cluster.html"><a href="case_cluster.html#which-method-has-the-smallest-standard-error"><i class="fa fa-check"></i><b>11.6.2</b> Which method has the smallest standard error?</a></li>
<li class="chapter" data-level="11.6.3" data-path="case_cluster.html"><a href="case_cluster.html#which-method-has-the-smallest-root-mean-squared-error"><i class="fa fa-check"></i><b>11.6.3</b> Which method has the smallest Root Mean Squared Error?</a></li>
<li class="chapter" data-level="11.6.4" data-path="case_cluster.html"><a href="case_cluster.html#do-the-methods-have-correctly-estimated-standard-errors"><i class="fa fa-check"></i><b>11.6.4</b> Do the methods have correctly estimated standard errors?</a></li>
<li class="chapter" data-level="11.6.5" data-path="case_cluster.html"><a href="case_cluster.html#did-we-have-enough-simulation-trials"><i class="fa fa-check"></i><b>11.6.5</b> Did we have enough simulation trials?</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="case_cluster.html"><a href="case_cluster.html#extending-to-a-multifactor-simulation"><i class="fa fa-check"></i><b>11.7</b> Extending to a multifactor simulation</a></li>
<li class="chapter" data-level="11.8" data-path="case_cluster.html"><a href="case_cluster.html#standardization-in-a-data-generating-process"><i class="fa fa-check"></i><b>11.8</b> Standardization in a data generating process</a></li>
<li class="chapter" data-level="11.9" data-path="case_cluster.html"><a href="case_cluster.html#making-analyze_data-quiet"><i class="fa fa-check"></i><b>11.9</b> Making analyze_data() quiet</a></li>
<li class="chapter" data-level="11.10" data-path="case_cluster.html"><a href="case_cluster.html#where-to-compute-performance-measures-inside-vs.-outside"><i class="fa fa-check"></i><b>11.10</b> Where to compute performance measures: inside vs. outside?</a></li>
<li class="chapter" data-level="11.11" data-path="case_cluster.html"><a href="case_cluster.html#run-the-simulation"><i class="fa fa-check"></i><b>11.11</b> Run the simulation</a></li>
<li class="chapter" data-level="11.12" data-path="case_cluster.html"><a href="case_cluster.html#analyzing-our-results"><i class="fa fa-check"></i><b>11.12</b> Analyzing our results</a>
<ul>
<li class="chapter" data-level="11.12.1" data-path="case_cluster.html"><a href="case_cluster.html#checking-on-convergence-issues"><i class="fa fa-check"></i><b>11.12.1</b> Checking on convergence issues</a></li>
<li class="chapter" data-level="11.12.2" data-path="case_cluster.html"><a href="case_cluster.html#calculating-standard-metrics"><i class="fa fa-check"></i><b>11.12.2</b> Calculating standard metrics</a></li>
<li class="chapter" data-level="11.12.3" data-path="case_cluster.html"><a href="case_cluster.html#bias-analysis"><i class="fa fa-check"></i><b>11.12.3</b> Bias analysis</a></li>
</ul></li>
<li class="chapter" data-level="11.13" data-path="case_cluster.html"><a href="case_cluster.html#exercises-2"><i class="fa fa-check"></i><b>11.13</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="error-trapping-and-other-headaches.html"><a href="error-trapping-and-other-headaches.html"><i class="fa fa-check"></i><b>12</b> Error trapping and other headaches</a>
<ul>
<li class="chapter" data-level="12.1" data-path="error-trapping-and-other-headaches.html"><a href="error-trapping-and-other-headaches.html#safe_code"><i class="fa fa-check"></i><b>12.1</b> Safe code</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="error-trapping-and-other-headaches.html"><a href="error-trapping-and-other-headaches.html#what-to-do-with-warnings"><i class="fa fa-check"></i><b>12.1.1</b> What to do with warnings</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="error-trapping-and-other-headaches.html"><a href="error-trapping-and-other-headaches.html#saving-files-and-results"><i class="fa fa-check"></i><b>12.2</b> Saving files and results</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="error-trapping-and-other-headaches.html"><a href="error-trapping-and-other-headaches.html#saving-simulations-as-you-go"><i class="fa fa-check"></i><b>12.2.1</b> Saving simulations as you go</a></li>
<li class="chapter" data-level="12.2.2" data-path="error-trapping-and-other-headaches.html"><a href="error-trapping-and-other-headaches.html#dynamically-making-directories"><i class="fa fa-check"></i><b>12.2.2</b> Dynamically making directories</a></li>
<li class="chapter" data-level="12.2.3" data-path="error-trapping-and-other-headaches.html"><a href="error-trapping-and-other-headaches.html#loading-and-combining-files-of-simulation-results"><i class="fa fa-check"></i><b>12.2.3</b> Loading and combining files of simulation results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="exp_design.html"><a href="exp_design.html"><i class="fa fa-check"></i><b>13</b> Designing the multifactor simulation experiment</a>
<ul>
<li class="chapter" data-level="13.1" data-path="exp_design.html"><a href="exp_design.html#choosing-parameter-combinations"><i class="fa fa-check"></i><b>13.1</b> Choosing parameter combinations</a></li>
<li class="chapter" data-level="13.2" data-path="exp_design.html"><a href="exp_design.html#using-pmap-to-run-multifactor-simulations"><i class="fa fa-check"></i><b>13.2</b> Using pmap to run multifactor simulations</a></li>
<li class="chapter" data-level="13.3" data-path="exp_design.html"><a href="exp_design.html#keeping-things-organized-and-the-source-command"><i class="fa fa-check"></i><b>13.3</b> Keeping things organized and the source command</a></li>
<li class="chapter" data-level="13.4" data-path="exp_design.html"><a href="exp_design.html#analyzing-results-from-a-multifactor-experiment"><i class="fa fa-check"></i><b>13.4</b> Analyzing results from a multifactor experiment</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="exp_design.html"><a href="exp_design.html#bundling"><i class="fa fa-check"></i><b>13.4.1</b> Bundling</a></li>
<li class="chapter" data-level="13.4.2" data-path="exp_design.html"><a href="exp_design.html#aggregation"><i class="fa fa-check"></i><b>13.4.2</b> Aggregation</a></li>
<li class="chapter" data-level="13.4.3" data-path="exp_design.html"><a href="exp_design.html#regression-summarization"><i class="fa fa-check"></i><b>13.4.3</b> Regression Summarization</a></li>
<li class="chapter" data-level="13.4.4" data-path="exp_design.html"><a href="exp_design.html#focus-on-subset-kick-rest-to-supplement"><i class="fa fa-check"></i><b>13.4.4</b> Focus on subset, kick rest to supplement</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="case-study-a-simulation-to-compare-different-estimators.html"><a href="case-study-a-simulation-to-compare-different-estimators.html"><i class="fa fa-check"></i><b>14</b> Case study: A simulation to compare different estimators</a>
<ul>
<li class="chapter" data-level="14.1" data-path="case-study-a-simulation-to-compare-different-estimators.html"><a href="case-study-a-simulation-to-compare-different-estimators.html#the-data-generating-process"><i class="fa fa-check"></i><b>14.1</b> The data generating process</a></li>
<li class="chapter" data-level="14.2" data-path="case-study-a-simulation-to-compare-different-estimators.html"><a href="case-study-a-simulation-to-compare-different-estimators.html#the-data-analysis-methods"><i class="fa fa-check"></i><b>14.2</b> The data analysis methods</a></li>
<li class="chapter" data-level="14.3" data-path="case-study-a-simulation-to-compare-different-estimators.html"><a href="case-study-a-simulation-to-compare-different-estimators.html#the-simulation-itself"><i class="fa fa-check"></i><b>14.3</b> The simulation itself</a></li>
<li class="chapter" data-level="14.4" data-path="case-study-a-simulation-to-compare-different-estimators.html"><a href="case-study-a-simulation-to-compare-different-estimators.html#calculating-performance-measures-for-all-our-estimators"><i class="fa fa-check"></i><b>14.4</b> Calculating performance measures for all our estimators</a></li>
<li class="chapter" data-level="14.5" data-path="case-study-a-simulation-to-compare-different-estimators.html"><a href="case-study-a-simulation-to-compare-different-estimators.html#improving-the-visualization-of-the-results"><i class="fa fa-check"></i><b>14.5</b> Improving the visualization of the results</a></li>
<li class="chapter" data-level="14.6" data-path="case-study-a-simulation-to-compare-different-estimators.html"><a href="case-study-a-simulation-to-compare-different-estimators.html#extension-the-bias-variance-tradeoff"><i class="fa fa-check"></i><b>14.6</b> Extension: The Bias-variance tradeoff</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="parallel-processing.html"><a href="parallel-processing.html"><i class="fa fa-check"></i><b>15</b> Parallel Processing</a>
<ul>
<li class="chapter" data-level="15.1" data-path="parallel-processing.html"><a href="parallel-processing.html#parallel-on-your-computer"><i class="fa fa-check"></i><b>15.1</b> Parallel on your computer</a></li>
<li class="chapter" data-level="15.2" data-path="parallel-processing.html"><a href="parallel-processing.html#parallel-off-your-computer"><i class="fa fa-check"></i><b>15.2</b> Parallel off your computer</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="parallel-processing.html"><a href="parallel-processing.html#what-is-a-command-line-interface"><i class="fa fa-check"></i><b>15.2.1</b> What is a command-line interface?</a></li>
<li class="chapter" data-level="15.2.2" data-path="parallel-processing.html"><a href="parallel-processing.html#running-a-job-on-a-cluster"><i class="fa fa-check"></i><b>15.2.2</b> Running a job on a cluster</a></li>
<li class="chapter" data-level="15.2.3" data-path="parallel-processing.html"><a href="parallel-processing.html#checking-on-a-job"><i class="fa fa-check"></i><b>15.2.3</b> Checking on a job</a></li>
<li class="chapter" data-level="15.2.4" data-path="parallel-processing.html"><a href="parallel-processing.html#running-lots-of-jobs-on-a-cluster"><i class="fa fa-check"></i><b>15.2.4</b> Running lots of jobs on a cluster</a></li>
<li class="chapter" data-level="15.2.5" data-path="parallel-processing.html"><a href="parallel-processing.html#resources-for-harvards-odyssey"><i class="fa fa-check"></i><b>15.2.5</b> Resources for Harvard’s Odyssey</a></li>
<li class="chapter" data-level="15.2.6" data-path="parallel-processing.html"><a href="parallel-processing.html#acknowledgements"><i class="fa fa-check"></i><b>15.2.6</b> Acknowledgements</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="case-study-the-power-and-validity-of-neymans-ate-estimate.html"><a href="case-study-the-power-and-validity-of-neymans-ate-estimate.html"><i class="fa fa-check"></i><b>16</b> Case study: The Power and Validity of Neyman’s ATE Estimate</a>
<ul>
<li class="chapter" data-level="16.1" data-path="case-study-the-power-and-validity-of-neymans-ate-estimate.html"><a href="case-study-the-power-and-validity-of-neymans-ate-estimate.html#step-1-write-a-function-for-a-specific-simulation-given-specific-parameters."><i class="fa fa-check"></i><b>16.1</b> Step 1: Write a function for a specific simulation given specific parameters.</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="case-study-the-power-and-validity-of-neymans-ate-estimate.html"><a href="case-study-the-power-and-validity-of-neymans-ate-estimate.html#running-our-single-trial-more-than-once"><i class="fa fa-check"></i><b>16.1.1</b> Running our single trial more than once</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="case-study-the-power-and-validity-of-neymans-ate-estimate.html"><a href="case-study-the-power-and-validity-of-neymans-ate-estimate.html#step-2-make-a-dataframe-of-all-experimental-combinations-desired"><i class="fa fa-check"></i><b>16.2</b> Step 2: Make a dataframe of all experimental combinations desired</a></li>
<li class="chapter" data-level="16.3" data-path="case-study-the-power-and-validity-of-neymans-ate-estimate.html"><a href="case-study-the-power-and-validity-of-neymans-ate-estimate.html#step-3-explore-results"><i class="fa fa-check"></i><b>16.3</b> Step 3: Explore results</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="case-study-the-power-and-validity-of-neymans-ate-estimate.html"><a href="case-study-the-power-and-validity-of-neymans-ate-estimate.html#visualizing-experimental-results"><i class="fa fa-check"></i><b>16.3.1</b> Visualizing experimental results</a></li>
<li class="chapter" data-level="16.3.2" data-path="case-study-the-power-and-validity-of-neymans-ate-estimate.html"><a href="case-study-the-power-and-validity-of-neymans-ate-estimate.html#looking-at-main-effects"><i class="fa fa-check"></i><b>16.3.2</b> Looking at main effects</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="case-study-the-power-and-validity-of-neymans-ate-estimate.html"><a href="case-study-the-power-and-validity-of-neymans-ate-estimate.html#addendum-saving-more-details"><i class="fa fa-check"></i><b>16.4</b> Addendum: Saving more details</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="case-study-the-power-and-validity-of-neymans-ate-estimate.html"><a href="case-study-the-power-and-validity-of-neymans-ate-estimate.html#getting-results-ready-for-analysis"><i class="fa fa-check"></i><b>16.4.1</b> Getting results ready for analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html"><i class="fa fa-check"></i><b>17</b> Design, analysis, and presentation of simulation results</a>
<ul>
<li class="chapter" data-level="17.1" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html#designing-the-simulation-experiment"><i class="fa fa-check"></i><b>17.1</b> Designing the simulation experiment</a></li>
<li class="chapter" data-level="17.2" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html#choosing-parameter-levels"><i class="fa fa-check"></i><b>17.2</b> Choosing parameter levels</a></li>
<li class="chapter" data-level="17.3" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html#presentation"><i class="fa fa-check"></i><b>17.3</b> Presentation</a></li>
<li class="chapter" data-level="17.4" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html#tabulation"><i class="fa fa-check"></i><b>17.4</b> Tabulation</a></li>
<li class="chapter" data-level="17.5" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html#visualization"><i class="fa fa-check"></i><b>17.5</b> Visualization</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html#example-1-biserial-correlation-estimation"><i class="fa fa-check"></i><b>17.5.1</b> Example 1: Biserial correlation estimation</a></li>
<li class="chapter" data-level="17.5.2" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html#example-2-variance-estimation-and-meta-regression"><i class="fa fa-check"></i><b>17.5.2</b> Example 2: Variance estimation and Meta-regression</a></li>
<li class="chapter" data-level="17.5.3" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html#example-heat-maps-of-coverage"><i class="fa fa-check"></i><b>17.5.3</b> Example: Heat maps of coverage</a></li>
</ul></li>
<li class="chapter" data-level="17.6" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html#modeling"><i class="fa fa-check"></i><b>17.6</b> Modeling</a></li>
<li class="chapter" data-level="17.7" data-path="design-analysis-and-presentation-of-simulation-results.html"><a href="design-analysis-and-presentation-of-simulation-results.html#presentation-1"><i class="fa fa-check"></i><b>17.7</b> Presentation</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="simulation-under-the-potential-outcomes-framework.html"><a href="simulation-under-the-potential-outcomes-framework.html"><i class="fa fa-check"></i><b>18</b> Simulation under the Potential Outcomes Framework</a>
<ul>
<li class="chapter" data-level="18.1" data-path="simulation-under-the-potential-outcomes-framework.html"><a href="simulation-under-the-potential-outcomes-framework.html#finite-vs.-superpopulation-inference"><i class="fa fa-check"></i><b>18.1</b> Finite vs. Superpopulation inference</a></li>
<li class="chapter" data-level="18.2" data-path="simulation-under-the-potential-outcomes-framework.html"><a href="simulation-under-the-potential-outcomes-framework.html#data-generation-processes-for-potential-outcomes"><i class="fa fa-check"></i><b>18.2</b> Data generation processes for potential outcomes</a></li>
<li class="chapter" data-level="18.3" data-path="simulation-under-the-potential-outcomes-framework.html"><a href="simulation-under-the-potential-outcomes-framework.html#finite-sample-performance-measures"><i class="fa fa-check"></i><b>18.3</b> Finite sample performance measures</a></li>
<li class="chapter" data-level="18.4" data-path="simulation-under-the-potential-outcomes-framework.html"><a href="simulation-under-the-potential-outcomes-framework.html#nested-finite-simulation-procedure"><i class="fa fa-check"></i><b>18.4</b> Nested finite simulation procedure</a></li>
<li class="chapter" data-level="18.5" data-path="simulation-under-the-potential-outcomes-framework.html"><a href="simulation-under-the-potential-outcomes-framework.html#calibrated-simulations-and-the-potential-outcomes-framework"><i class="fa fa-check"></i><b>18.5</b> Calibrated simulations and the potential outcomes framework</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="simulations-as-evidence.html"><a href="simulations-as-evidence.html"><i class="fa fa-check"></i><b>19</b> Simulations as evidence</a>
<ul>
<li class="chapter" data-level="19.1" data-path="simulations-as-evidence.html"><a href="simulations-as-evidence.html#use-extensive-multi-factor-simulations"><i class="fa fa-check"></i><b>19.1</b> Use extensive multi-factor simulations</a></li>
<li class="chapter" data-level="19.2" data-path="simulations-as-evidence.html"><a href="simulations-as-evidence.html#beat-them-at-their-own-game"><i class="fa fa-check"></i><b>19.2</b> Beat them at their own game</a></li>
<li class="chapter" data-level="19.3" data-path="simulations-as-evidence.html"><a href="simulations-as-evidence.html#calibrated-simulations"><i class="fa fa-check"></i><b>19.3</b> Calibrated simulations</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="the-parametric-bootstrap.html"><a href="the-parametric-bootstrap.html"><i class="fa fa-check"></i><b>20</b> The Parametric bootstrap</a>
<ul>
<li class="chapter" data-level="20.1" data-path="the-parametric-bootstrap.html"><a href="the-parametric-bootstrap.html#air-conditioners-a-stolen-case-study"><i class="fa fa-check"></i><b>20.1</b> Air conditioners: a stolen case study</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Designing Monte Carlo Simulations in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="performance-criteria" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapter 7</span> Performance criteria<a href="performance-criteria.html#performance-criteria" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>So far, we’ve looked at the structure of simulation studies and seen how to write functions that generate data according to a specified model (and parameters) and functions that implement estimation procedures on simulated data.
Put those two together and repeat a bunch of times, and we’ll have a lot of estimates and perhaps also their estimated standard errors and/or confidence intervals. And if the purpose of the simulation is to compare <em>multiple</em> estimation procedures, then we’ll have a set of estimates (SEs, CIs, etc.) for <em>each</em> of the procedures. The question is then: how do we assess the performance of these estimators?</p>
<p>In this chapter, we’ll look at a variety of <strong>performance criteria</strong> that are commonly used to compare the relative performance of multiple estimators or measure how well an estimator works.
These performance criteria are all assessments of how the estimator behaves if you repeat the experimental process an infinite number of times.
In statistical terms, these criteria are summaries of the true sampling distribution of the estimator, given a specified data generating process.</p>
<p>Although we can’t observe this sampling distribution directly (and it can only rarely be worked out in full mathematical detail), we can <em>sample</em> from it.
In particular, the set of estimates generated from a simulation constitute a (typically large) sample from the sampling distribution of an estimator. (Say that six times fast!)
We then use that sample to <em>estimate</em> the performance criteria of interest.
For example, we want to know what percent of the time we would reject the null hypothesis; we estimate this by seeing how often we do in 1000 trials.
Now, because we have only a sample of trials rather than the full distribution, our estimates are estimates.
In other words, they can be wrong, just due to random chance.
We can describe how wrong with the <strong>Monte Carlo standard error (MCSE)</strong>; it is the standard error in our estimation of performance due to the simulation only having a finite number of trials.
Just as with statistical uncertainty when analyzing data, we can estimate our MCSE and even generate confidence intervals for our performance estimates with them.
And then, if we can computationally do it, we would use a large enough number of replications so that the MCSE is small enough that our performance estimates have our desired level of precision.</p>
<div id="inference-vs.-estimation" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Inference vs. Estimation<a href="performance-criteria.html#inference-vs.-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A core purpose of simulation is to compare different estimators to each other under a variety of circumstances.
These sorts of simulations are simulations to examine and compare the properties of different inferential methods or estimators.
For example, one might want to know how much better adjusting for covariates is, if at all, when analyzing a randomized experiment.</p>
<p>Such an analysis might involve two general activities: inference and estimation.
<em>Inference</em> is when we do hypothesis testing, asking whether there is evidence for some sort of effect, or asking whether there is evidence that some coefficient is greater than or less than some specified value.
So in our circumstance, we might specify interest in the average treatment effect, which we will call <span class="math inline">\(\tau\)</span>.
Inference would be testing the null of <span class="math inline">\(H_0: \tau = 0\)</span>.</p>
<p><em>Estimation</em> is when we estimate the actual value of <span class="math inline">\(\tau\)</span>.
There might be different ways of obtaining some estimate, and we want to know which is best.
Hand-in-hand with estimation is estimating uncertainty, i.e. assessing how close we believe our estimate to be to the truth.
Here we would examine how well, for example, different estimators of the standard error perform.</p>
<p>For our hypothetical scenario, we might consider using either of two estimators of interest, the simple difference in means,
<span class="math display">\[ \hat{\tau}_{sd} = \overline{Y}_1 - \overline{Y}_0,  \]</span>
where <span class="math inline">\(\overline{Y}_z\)</span> is the average outcome of those units given treatment <span class="math inline">\(z\)</span>, versus the coefficient <span class="math inline">\(\widehat{\tau}_{ols}\)</span> from fitting the ordinary regression:
<span class="math display">\[ Y = a + b X + \tau Z + \epsilon .\]</span></p>
<p>Call these two Estimator A and Estimator B.
For <span class="math inline">\(\hat{\tau}_{sd}\)</span> we would use Neyman’s formula for estimating the standard error:
<span class="math display">\[ \widehat{SE}(\tau_{sd} ) = \frac{ \hat{\sigma}_1^2 }{ n_1 } + \frac{ \hat{\sigma}_0^2}{n_0} . \]</span>
For <span class="math inline">\(\widehat{\tau}_{ols}\)</span> we might use, say, the usual standard errors we get from generic statistics software.
Finally, for inference, we would perhaps use the <span class="math inline">\(p\)</span>-value from a Wald test for our simple difference in means and the <span class="math inline">\(p\)</span>-values we get from the regression command.</p>
<p>The question would then be whether our two estimation strategies were different, whether one was superior to the other, and what salient differences were.
In particular, for our simple example, we might want to know if there is evidence that there is a treatment effect at all.
This would be inference.
We might also want to know what the average treatment effect is. This is estimation.
These two goals are clearly highly related – if we have a good estimate of the treatment effect and it is not zero, then we are willing to say that there is a treatment effect – but depending on the framing, the way you would set up a simulation to investigate the behavior of your estimators will be different.</p>
<p>For inference, we first might ask whether both our methods are valid, i.e., ask whether these methods work correctly when we test for a treatment effect when there is none.
In particular, we might wonder whether adjusting for a covariate could open the door to inference problems if there was no actual treatment effect, but where the residuals had some non-normal distribution.
These sorts of questions are questions of validity.</p>
<p>Also for inference, we might ask which method is better for detecting an effect when there is one.
Here, we want to know how these estimators perform in circumstances with a non-zero average treatment effect.
Do they reject the null often, or rarely?
How much does including covariates increase our chances of rejection?
These are questions about power.</p>
<p>For estimation, we can be concerned with two things: bias and variance.
An estimator is biased if it would generally give estimates that are higher (or lower) than the parameter being estimated.
The variance of an estimator is how much the estimator varies from trial to trial.
The variance is the true standard error, squared.</p>
<p>We might also be concerned with how well we can estimate the uncertainty of our estimators (i.e., estimate our standard error).
For example, we might have an estimator that works very well, but we have no ability to estimate how well in any given circumstance.</p>
</div>
<div id="evaluation-of-estimation-methods" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Evaluation of Estimation Methods<a href="performance-criteria.html#evaluation-of-estimation-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Estimation has two major components, the point estimator and the uncertainty estimator.
We evaluate both the properties of the point estimator and the performance of the properties of the point estimator.
For example, consider a specific estimate <span class="math inline">\(\hat{\tau}\)</span> of our average treatment effect.
We first wish to know the actual bias and true standard error (<span class="math inline">\(SE\)</span>) of <span class="math inline">\(\hat{\tau}\)</span>.
These are its actual properties.
However, for each estimated <span class="math inline">\(\hat{\tau}\)</span>, we also estimate <span class="math inline">\(\widehat{SE}\)</span>, as our estimated measure of how precise our estimate is.
We need to understand the properties of <span class="math inline">\(\widehat{SE}\)</span> as well.</p>
<div id="assessing-actual-properties" class="section level3 hasAnchor" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Assessing actual properties<a href="performance-criteria.html#assessing-actual-properties" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>These are simple.
For a given scenario, we repeatedly generate data and estimate effects.
We then take the mean and standard deviation of these repeated trials to estimate actual properties via Monte Carlo.
Given sufficient simulation trials, we can obtain arbitrarily accurate measures.</p>
<p>For example, we can ask what the variance (or standard error) of our estimator is.
We can ask if our estimator is biased.
We can ask what the overall <span class="math inline">\(RMSE\)</span> (root mean squared error) of our estimator is.</p>
</div>
<div id="assessing-estimated-properties" class="section level3 hasAnchor" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Assessing estimated properties<a href="performance-criteria.html#assessing-estimated-properties" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let our estimator be <span class="math inline">\(\hat{\tau}\)</span>. In our simulation we can know its actual properties, but if we were to use this estimator in practice we would have to also estimate its associated standard error, and generate confidence intervals and so forth.
To understand if this works, we need to evaluate not only the behavior of the estimator itself, but the behavior of these associated things.</p>
</div>
</div>
<div id="assessing-a-point-estimator" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Assessing a point estimator<a href="performance-criteria.html#assessing-a-point-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consider an estimator <span class="math inline">\(T\)</span> for a parameter <span class="math inline">\(\theta\)</span>.
A simulation study generates a (typically large) sample of estimates <span class="math inline">\(T_1,...,T_R\)</span>, all of the target <span class="math inline">\(\theta\)</span>.</p>
<p>The most common measures of an estimator are the bias, variance, and mean squared error.
We can first assess whether our estimator is biased, by comparing the mean of our <span class="math inline">\(R\)</span> estimates
<span class="math display">\[ \bar{T} = \frac{1}{R}\sum_{r=1}^R T_r \]</span>
to <span class="math inline">\(\theta\)</span>.
The bias of our estimator is <span class="math inline">\(bias = \bar{T} - \theta\)</span>.</p>
<p>We can also ask how variable our estimator is, by assessing the size of the variance of our <span class="math inline">\(R\)</span> estimates
<span class="math display">\[\displaystyle{S_T^2 = \frac{1}{R - 1}\sum_{r=1}^R \left(T_r - \bar{T}\right)^2} . \]</span></p>
<p>Finally, the Mean Square Error (MSE) is a combination of the above two measures:
<span class="math display">\[ MSE = \frac{1}{R} \sum_{r = 1}^R \left( T_r - \theta\right)^2 . \]</span></p>
<p>An important relationship connecting these three measures is
<span class="math display">\[ MSE = bias^2 + variance .\]</span>
Less commonly used criteria include the median bias and the median absolute deviation of <span class="math inline">\(T\)</span>, where we use the median <span class="math inline">\(\tilde{T}\)</span> of our estimates rather than the mean <span class="math inline">\(\bar{T}\)</span>.</p>
<p>All these criteria are listed in the table below.</p>
<table>
<colgroup>
<col width="25%" />
<col width="38%" />
<col width="36%" />
</colgroup>
<thead>
<tr class="header">
<th>Criterion</th>
<th>Definition</th>
<th>Estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bias</td>
<td><span class="math inline">\(\text{E}(T) - \theta\)</span></td>
<td><span class="math inline">\(\bar{T} - \theta\)</span></td>
</tr>
<tr class="even">
<td>Median bias</td>
<td><span class="math inline">\(\text{M}(T) - \theta\)</span></td>
<td><span class="math inline">\(\tilde{T} - \theta\)</span></td>
</tr>
<tr class="odd">
<td>Variance</td>
<td><span class="math inline">\(\text{E}\left[\left(T - \text{E}(T)\right)^2\right]\)</span></td>
<td><span class="math inline">\(S_T^2\)</span></td>
</tr>
<tr class="even">
<td>MSE</td>
<td><span class="math inline">\(\text{E}\left[\left(T - \theta\right)^2\right]\)</span></td>
<td><span class="math inline">\(\left(\bar{T} - \theta\right)^2 + S_T^2\)</span></td>
</tr>
<tr class="odd">
<td>MAD</td>
<td><span class="math inline">\(\text{M}\left[\left|T - \theta\right|\right]\)</span></td>
<td><span class="math inline">\(\left[\left|T - \theta\right|\right]_{R/2}\)</span></td>
</tr>
</tbody>
</table>
<ul>
<li>Bias and median bias are measures of whether the estimator is systematically higher or lower than the target parameter.</li>
<li>Variance is a measure of the <strong>precision</strong> of the estimator—that is, how far it deviates <em>from its average</em>. We might look at the square root of this, to assess the precision in the units of the original measure.</li>
<li>Mean-squared error is a measure of <strong>overall accuracy</strong>, i.e. is a measure how far we typically are from the truth. We more frequently use the root mean-squared error, or RMSE, which is just the square root of the MSE.</li>
<li>The median absolute deviation is another measure of overall accuracy that is less sensitive to an occasional bad mistake. In general the RMSE can be driven up by a single bad egg. The MAD is less sensitive to this.</li>
</ul>
<p>For absolute assessments of performance, an estimator with low bias, low variance, and thus low RMSE is desired.
For comparisons of relative performance, an estimator with lower RMSE is usually preferable to an estimator with higher RMSE; if two estimators have comparable RMSE, then the estimator with lower bias (or median bias) would usually be preferable.</p>
<p>It is important to recognize that the above performance measures depend on the scale of the parameter.
For example, if our estimators are measuring a treatment impact in dollars, then our bias would be in dollars.
Our variance and MSE would be in dollars squared, so we might take their square roots to put them back on the dollars scale.</p>
<p>Usually in a simulation, the scale of the outcome is irrelevant as we are comparing one estimator to the other.
To ease interpretation, we might want to assess estimators relative to the baseline variation.
To achieve this, we can generate data so the outcome has unit variance (i.e., we generate <em>standardized data</em>).
Then the bias, median bias, and root mean-squared error would all be in standard deviation units.</p>
<p>Furthermore, changing the scale of a parameter can lead to nonlinear changes in the performance measures.
For instance, suppose that <span class="math inline">\(\theta\)</span> is a measure of the proportion of time that a behavior occurs.
A natural way to transform this parameter would be to put it on the log-odds (logit) scale.
However, because of the nonlinear aspect of the logit,
<span class="math display">\[\text{Bias}\left[\text{logit}(T)\right] \neq \text{logit}\left(\text{Bias}[T]\right), \qquad \text{MSE}\left[\text{logit}(T)\right] \neq \text{logit}\left(\text{MSE}[T]\right),\]</span>
and so on.
This is fine, but one should be aware that this can happen and do it on purpose.</p>
</div>
<div id="assessing-a-standard-error-estimator" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Assessing a standard error estimator<a href="performance-criteria.html#assessing-a-standard-error-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Statistics is perhaps more about assessing how good an estimate is than making an estimate in the first place.
This translates to simulation studies: we generally not only want to know whether our estimator is doing a good job, but we often want to know whether we are able to get a good standard error for that estimator as well.</p>
<p>We first would compare the expected value of <span class="math inline">\(\widehat{SE}\)</span> to the actual <span class="math inline">\(SE\)</span>.
This tells us whether our uncertainty estimates are biased.
We could also examine the standard deviation of <span class="math inline">\(\widehat{SE}\)</span>, which tells us whether our estimates of uncertainty are relatively stable (especially compared to other methods).
We finally could examine whether there is correlation between <span class="math inline">\(\widehat{SE}\)</span> and actual error (e.g., <span class="math inline">\(\left|T - \theta \right|\)</span>).
Good estimates of uncertainty should predict error in a given context (especially if calculating in conditional estimates).
See .</p>
<p>For the first assessment, we usually assess the quality of a standard error estimator with a relative performance criteria, rather than an absolute one as we saw above.
For an example, suppose that in our simulation we are examining the performance of a point-estimator <span class="math inline">\(T\)</span> for a parameter <span class="math inline">\(\theta\)</span> along with an estimator <span class="math inline">\(\widehat{SE}\)</span> for the standard error of <span class="math inline">\(T\)</span>.
In this case, we likely do not know the true standard error of <span class="math inline">\(T\)</span>, for our simulation context, prior to the simulation.
However, we can use the variance of <span class="math inline">\(T\)</span> across the replications (<span class="math inline">\(S_T^2\)</span>) to directly estimate the true sampling variance <span class="math inline">\(\text{Var}(T) = SE^2(T)\)</span>.
The <em>relative bias</em> of <span class="math inline">\(\widehat{SE}^2\)</span> would then be estimated by <span class="math inline">\(RB = \bar{V} / S_T^2\)</span>, where <span class="math inline">\(\bar{V}\)</span> is the average of <span class="math inline">\(\widehat{SE}^2\)</span> across simulation runs.
Note that a value of 1 for relative bias corresponds to exact unbiasedness.
The relative bias measure is a measure of <em>proportionate</em> under- or over-estimation.
For example, a relative bias of 1.12 would mean the standard error was, on average, 12% too large.</p>
<p>For parameters such as these, that measure scale, or that are always strictly positive, it often makes sense to quantify performance using such <em>relative</em> criteria.
Relative criteria are very similar to the absolutre criteria discussed for point estimators, but are defined as proportions of the target parameter, rather than as differences.
Relative criteria are also often used when, for example, estimating quantities such as standard deviations.
The table below defines several relative performance criteria.</p>
<table>
<colgroup>
<col width="25%" />
<col width="36%" />
<col width="37%" />
</colgroup>
<thead>
<tr class="header">
<th>Criterion</th>
<th>Definition</th>
<th>Estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Relative bias</td>
<td><span class="math inline">\(\text{E}(T) / \theta\)</span></td>
<td><span class="math inline">\(\bar{T} / \theta\)</span></td>
</tr>
<tr class="even">
<td>Relative median bias</td>
<td><span class="math inline">\(\text{M}(T) / \theta\)</span></td>
<td><span class="math inline">\(\tilde{T} / \theta\)</span></td>
</tr>
<tr class="odd">
<td>Relative MSE</td>
<td><span class="math inline">\(\text{E}\left[\left(T - \theta\right)^2\right] / \theta^2\)</span></td>
<td><span class="math inline">\(\frac{\left(\bar{T} - \theta\right)^2 + S_T^2}{\theta^2}\)</span></td>
</tr>
</tbody>
</table>
<div id="why-not-assess-widehatse-directly" class="section level3 hasAnchor" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Why not assess <span class="math inline">\(widehat{SE}\)</span> directly?<a href="performance-criteria.html#why-not-assess-widehatse-directly" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We typically see assessment of <span class="math inline">\(\widehat{SE}^2\)</span>, not <span class="math inline">\(\widehat{SE}\)</span>.
In other words, we typically work with assessing whether the variance estimator is unbiased, etc., rather than the standard error estimator.
This comes out of a few reasons.
First, in practice, so-called unbiased standard errors usually are not in fact actually unbiased.
For linear regression, for example, the classic standard error estimator is an unbiased <em>variance</em> estimator, meaning that we have a small amount of bias due to the square-rooting as:</p>
<p><span class="math display">\[ E[ \sqrt{ V } ] \neq \sqrt{ E[ V ] } . \]</span></p>
<p>Variance is also the component that gives us the classic bias-variance breakdown of $ MSE = Variance + Bias^2$, so if we are trying to assign whether an overall MSE is due to instability or systematic bias, operating in this squared space may be preferable.</p>
<p>That being said, to put things in terms of performance criteria humans understand it is usually nicer to put final evaluation metrics back into standard error units.
For example, saying there is a 10% reduction in the standard error is more meaningful (even if less impressive sounding) than saying there is a 19% reduction in the variance.</p>
</div>
</div>
<div id="assessing-a-hypothesis-testing-procedure" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Assessing a hypothesis testing procedure<a href="performance-criteria.html#assessing-a-hypothesis-testing-procedure" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When hypothesis tests are used in practice, the researcher specifies a null (e.g., no treatment effect), collects data, and generates a <span class="math inline">\(p\)</span>-value which is a measure of how extreme the observed data are from what we would expect to naturally occur, if the null were true.
When we assess a method for hypothesis testing, we are therefore typically concerned with two aspects: <em>validity</em> and <em>power</em>.</p>
<div id="validity" class="section level3 hasAnchor" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> Validity<a href="performance-criteria.html#validity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Validity revolves around whether we erroneously reject the null when it is in fact true more than we should.
Put another way, we say an inference method is valid if it has no more than an <span class="math inline">\(\alpha\)</span> chance of rejecting the null when we are testing at the <span class="math inline">\(\alpha\)</span> level.
This means if we used this method 1000 times, where the null was true for all of those 1000 times, we should not see more than about <span class="math inline">\(1000 \alpha\)</span> rejections (so, 50, if we were using the classic <span class="math inline">\(\alpha = 0.05\)</span> rule).</p>
<p>To do this we would specify a data generating process where the null is in fact true.
We then, for a series of such data sets with a true null, conduct our inferential processes on the data, record the <span class="math inline">\(p\)</span>-value, and score whether we reject the null hypothesis or not.</p>
<p>We might then test our methods by exploring more extreme data generation processes, where the null is true but other aspects of the data (such as outliers or heavy skew) make estimation difficult.
This allows us to understand if our methods are robust to strange data patterns in finite sample contexts.</p>
<p>The key concept for validity is that the date we generate, no matter how we do it, is data with a true null.
We then check to see if we reject the null more than we should.</p>
</div>
<div id="power" class="section level3 hasAnchor" number="7.5.2">
<h3><span class="header-section-number">7.5.2</span> Power<a href="performance-criteria.html#power" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Power is, loosely speaking, how often we notice an effect when one is there.
This is a much more nebulous concept, because some effects are clearly easier to notice than others. Regardless of the estimator used, if the effect is large enough, we would notice.
If we are comparing estimators to each other, this is less of a concern, because we are typically interested an relative performance. That being said, in order to generate data for a power evaluation, we have to generate data where there is something to detect.
In other words, we need to commit to what the alternative is, and this can be a tricky business.</p>
<p>Typically, it is best to think of power as a function of sample size or effect size. Therefore, we will typically examine a sequence of scenarios with steadily increasing sample size or effect size, estimating the power for each scenario in the sequence.
We then, for each sample in our series, estimate the power by the same process as for Validity, above.
For each series we can then plot power curves, as we saw with some of our earlier vignettes.</p>
<p>When assessing validity, we want rejection rates to be low, below <span class="math inline">\(\alpha\)</span>, and when assessing power we want them to be as high as possible. But the simulation process itself, other than the data generating process, is exactly the same.</p>
<p>To put some technical terms to this framing, for both validity and power assessment the main performance criterion is the <strong>rejection rate</strong> of the hypothesis test. When the data are simulated from a model in which the null hypothesis being tested is true, then the rejection rate is equivalent to the <strong>Type-I error rate</strong> of the test. When the data are simulated from a model in which the null hypothesis is false, then the rejection rate is equivalent to the <strong>power</strong> of the test (for given, non-null parameter values).
Ideally, a testing procedure should have actual Type-I error equal to the nominal level <span class="math inline">\(\alpha\)</span> (this is the definition of validity), but such exact tests are rare.</p>
<p>There are some different perspectives on how close the actual Type-I error rate should be in order to qualify as suitable for use in practice. Following a strict statistical definition, a hypothesis testing procedure is said to be <strong>level-<span class="math inline">\(\alpha\)</span></strong> if its actual Type-I error rate is <em>always</em> less than or equal to <span class="math inline">\(\alpha\)</span>.
Among a set of level-<span class="math inline">\(\alpha\)</span> tests, the test with highest power would be preferred.
If looking only at null rejection rates, then the test with Type-I error closest to <span class="math inline">\(\alpha\)</span> would usually be preferred.
A less stringent criteria is sometimes used instead, where type I error would be considered acceptable if it is within 50% of the desired <span class="math inline">\(\alpha\)</span>.</p>
<p>Often, it is of interest to evaluate the performance of the test at several different <span class="math inline">\(\alpha\)</span> levels.
A convenient way to calculate a set of different rejection rates is to record the simulated <span class="math inline">\(p\)</span>-values and then calculate from those.
To illustrate, suppose that <span class="math inline">\(P_r\)</span> is the <span class="math inline">\(p\)</span>-value from simulation replication <span class="math inline">\(k\)</span>, for <span class="math inline">\(k = 1,...,R\)</span>.
Then the rejection rate for a level-<span class="math inline">\(\alpha\)</span> test is defined as <span class="math inline">\(\rho_\alpha = \text{Pr}\left(P_r &lt; \alpha\right)\)</span> and estimated as
<span class="math display">\[r_\alpha = \frac{1}{R} \sum_{r=1}^R I(P_r &lt; \alpha).\]</span></p>
</div>
</div>
<div id="assessing-confidence-intervals" class="section level2 hasAnchor" number="7.6">
<h2><span class="header-section-number">7.6</span> Assessing confidence intervals<a href="performance-criteria.html#assessing-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Some estimation procedures result in confidence intervals (or sets) which are ranges of values that should contain the true answer with some specified degree of confidence.
For example, a normal-based confidence interval is a combination of an estimator and it’s estimated uncertainty.</p>
<p>We typically score a confidence interval along two dimensions, <strong>coverage rate</strong> and the <strong>average length</strong>.
To calculate coverage rate, we score whether each interval “captured” the true parameter.
A success is if the true parameter is inside the interval.
To calculate average length, we record each confidence interval’s length, and then average across simulation runs.
We say an estimator has good properties if it has good coverage, i.e. it is capturing the true value at least <span class="math inline">\(1-\alpha\)</span> of the time, and if it is generally short (i.e., the average length of the interval is less than the average length for other methods).</p>
<p>Note that confidence interval coverage is simultaneously evaluating the estimators in terms of how well they estimate (precision) and their inferential properties.
We have combined inference and estimation here.</p>
<p>Suppose that the confidence intervals are for the target parameter <span class="math inline">\(\theta\)</span> and have coverage level <span class="math inline">\(\beta\)</span>.
Let <span class="math inline">\(A_r\)</span> and <span class="math inline">\(B_r\)</span> denote the lower and upper end-points of the confidence interval from simulation replication <span class="math inline">\(k\)</span>, and let <span class="math inline">\(W_r = B_r - A_r\)</span>, all for <span class="math inline">\(k = 1,...,R\)</span>.
The coverage rate and average length criteria are then as defined in the table below.</p>
<table>
<colgroup>
<col width="18%" />
<col width="57%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th>Criterion</th>
<th>Definition</th>
<th>Estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Coverage</td>
<td><span class="math inline">\(\omega_\beta = \text{Pr}(A \leq \theta \leq B)\)</span></td>
<td><span class="math inline">\(\frac{1}{R}\sum_{r=1}^R I(A_r \leq \theta \leq B_r)\)</span></td>
</tr>
<tr class="even">
<td>Expected length</td>
<td><span class="math inline">\(\text{E}(W) = \text{E}(B - A)\)</span></td>
<td><span class="math inline">\(\bar{W} = \bar{B} - \bar{A}\)</span></td>
</tr>
</tbody>
</table>
<p>Just as with hypothesis testing, a strict statistical interpretation would deem a hypothesis testing procedure acceptable if it has actual coverage rate greater than or equal to <span class="math inline">\(\beta\)</span>.
If multiple tests satisfy this criterion, then the test with the lowest expected length would be preferable. Some analysts prefer to look at lower and upper coverage separately, where lower coverage is <span class="math inline">\(\text{Pr}(A \leq \theta)\)</span> and upper coverage is <span class="math inline">\(\text{Pr}(\theta \leq B)\)</span>.</p>
</div>
<div id="uncertainty-in-our-performance-estimates-the-mcse" class="section level2 hasAnchor" number="7.7">
<h2><span class="header-section-number">7.7</span> Uncertainty in our performance estimates (the MCSE)<a href="performance-criteria.html#uncertainty-in-our-performance-estimates-the-mcse" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Our performance criteria are defined as average performance across an infinite number of trials.
Of course, in our simulations we only run a finite number, and estimate the performance criteria with the sample of trials we generate.
For example, if we are assessing coverage across 100 trials, we calculate what fraction rejected the null for that 100.
But due to random chance, we might see a higher, or lower proportion rejected just due to random chance than what we would see if we ran the simulation forever.</p>
<p>To account for this estimation uncertainty we would want to calculate associated uncertainty estimates to go with our point estimates of performance.
We want to, in other words, treat our simulation results as a dataset in its own right.</p>
<p>In this section we discuss how to calculate standard errors for the various performance critera given above.
We call these Monte Carlo Simulation Errors, or MCSEs.
For many performance critera, calculating a MCSE is quite straightforward: we have a nice, independent and identically distributed set of measurements, and the statastical inference is straightforward.
For some other performance criteria we have to be a bit more clever.</p>
<p>First, we list MCSE expressions for many of our straightforward performance measures on the table below.
In reading the table, recall that, for an estimator <span class="math inline">\(T\)</span>, we have <span class="math inline">\(S_T^2\)</span> being the variance of <span class="math inline">\(T\)</span> across our simulation runs.
We also have
- Sample skewness (standardized): <span class="math inline">\(\displaystyle{g_T = \frac{1}{R S_T^3}\sum_{r=1}^R \left(T_r - \bar{T}\right)^3}\)</span>
- Sample kurtosis (standardized): <span class="math inline">\(\displaystyle{k_T = \frac{1}{R S_T^4} \sum_{r=1}^R \left(T_r - \bar{T}\right)^4}\)</span></p>
<table>
<colgroup>
<col width="66%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th>Criterion</th>
<th>MCSE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bias</td>
<td><span class="math inline">\(\sqrt{S_T^2/ R}\)</span></td>
</tr>
<tr class="even">
<td>Median bias</td>
<td>-</td>
</tr>
<tr class="odd">
<td>Variance</td>
<td><span class="math inline">\(\displaystyle{S_T^2 \sqrt{\frac{k_T - 1}{R}}}\)</span></td>
</tr>
<tr class="even">
<td>MSE</td>
<td><span class="math inline">\(\displaystyle{\sqrt{\frac{1}{R}\left[S_T^4 (k_T - 1) + 4 S_T^3 g_T\left(\bar{T} - \theta\right) + 4 S_T^2 \left(\bar{T} - \theta\right)^2\right]}}\)</span></td>
</tr>
<tr class="odd">
<td>MAD</td>
<td>-</td>
</tr>
<tr class="even">
<td>—————-</td>
<td>——–</td>
</tr>
<tr class="odd">
<td>Relative bias</td>
<td><span class="math inline">\(\sqrt{S_T^2 / \left(R\theta^2\right)}\)</span></td>
</tr>
<tr class="even">
<td>Relative median bias</td>
<td>-</td>
</tr>
<tr class="odd">
<td>Relative MSE</td>
<td><span class="math inline">\(\displaystyle{\sqrt{\frac{1}{R\theta^2}\left[S_T^4 (k_T - 1) + 4 S_T^3 g_T\left(\bar{T} - \theta\right) + 4 S_T^2 \left(\bar{T} - \theta\right)^2\right]}}\)</span></td>
</tr>
<tr class="even">
<td>—————-</td>
<td>——–</td>
</tr>
<tr class="odd">
<td>Power &amp; Validity</td>
<td><span class="math inline">\(\sqrt{ r_\alpha \left(1 - r_\alpha\right) / R}\)</span></td>
</tr>
<tr class="even">
<td>Coverage</td>
<td><span class="math inline">\(\sqrt{\omega_\beta \left(1 - \omega_\beta\right) / R}\)</span></td>
</tr>
<tr class="odd">
<td>Expected length</td>
<td><span class="math inline">\(\sqrt{S_W^2 / R}\)</span></td>
</tr>
</tbody>
</table>
<div id="mcse-for-variance-estimators" class="section level3 hasAnchor" number="7.7.1">
<h3><span class="header-section-number">7.7.1</span> MCSE for variance estimators<a href="performance-criteria.html#mcse-for-variance-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Estimating the MCSE of the relative bias or relative MSE of a (squared) standard error estimator is complicated by the appearance of a sample quantity, <span class="math inline">\(S_T^2\)</span>, in the denominator of the ratio.
This renders the formula above unusable, technically speaking.</p>
<p>To properly assess the overall MCSE, we need to take the uncertainty of our denominator into account. One way to do so is to use the <em>jackknife</em> technique.
Let <span class="math inline">\(\bar{V}_{(j)}\)</span> and <span class="math inline">\(S_{T(j)}^2\)</span> be the average squared standard error estimate and the true variance estimate calculated from the set of replicates <strong><em>that excludes replicate <span class="math inline">\(j\)</span></em></strong>, for <span class="math inline">\(j = 1,...,R\)</span>.
The relative bias estimate, excluding replicate <span class="math inline">\(j\)</span> would then be <span class="math inline">\(\bar{V}_{(j)} / S_{T(j)}^2\)</span>.
Calculating all <span class="math inline">\(R\)</span> versions of this relative bias estimate and taking the variance yields the jackknife variance estimator:</p>
<p><span class="math display">\[
MCSE\left(\widehat{SE}^2\right) = \frac{1}{R} \sum_{j=1}^R \left(\frac{\bar{V}_{(j)}}{S_{T(j)}^2} - \frac{\bar{V}}{S_T^2}\right)^2.
\]</span></p>
<p>This would be quite time-consuming to compute if we did it by brute force. However, with a few algebra tricks we can find a much quicker way. The tricks come from observing that</p>
<p><span class="math display">\[
\begin{aligned}
\bar{V}_{(j)} &amp;= \frac{1}{R - 1}\left(R \bar{V} - V_j\right) \\
S_{T(j)}^2 &amp;= \frac{1}{R - 2} \left[(R - 1) S_T^2 - \frac{R}{R - 1}\left(T_j - \bar{T}\right)^2\right]
\end{aligned}
\]</span>
These formulas can be used to avoid re-computing the mean and sample variance from every subsample.
Instead, you calculate the overall mean and overall variance, and then do a small adjustment with each jackknife iteration.
You can even implement this with vector processing in R!</p>
</div>
<div id="the-simhelpers-package-and-mcses" class="section level3 hasAnchor" number="7.7.2">
<h3><span class="header-section-number">7.7.2</span> The simhelpers package and MCSEs<a href="performance-criteria.html#the-simhelpers-package-and-mcses" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <code>simhelper</code> package is designed to calculate MCSEs (and the performance metrics themselves) for you.
It is easy to use: here is an example on the Welch dataset that the package provides:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="performance-criteria.html#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>( simhelpers )</span>
<span id="cb137-2"><a href="performance-criteria.html#cb137-2" aria-hidden="true" tabindex="-1"></a>welch <span class="ot">&lt;-</span> welch_res <span class="sc">%&gt;%</span></span>
<span id="cb137-3"><a href="performance-criteria.html#cb137-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>( method <span class="sc">==</span> <span class="st">&quot;t-test&quot;</span> ) <span class="sc">%&gt;%</span></span>
<span id="cb137-4"><a href="performance-criteria.html#cb137-4" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">select</span>( <span class="sc">-</span>method, <span class="sc">-</span>seed, <span class="sc">-</span>iterations )</span>
<span id="cb137-5"><a href="performance-criteria.html#cb137-5" aria-hidden="true" tabindex="-1"></a>welch</span></code></pre></div>
<pre><code>## # A tibble: 8,000 × 8
##       n1    n2 mean_diff      est    var p_val lower_bound upper_bound
##    &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
##  1    50    50         0  0.0258  0.0954 0.934      -0.587       0.639
##  2    50    50         0  0.00516 0.0848 0.986      -0.573       0.583
##  3    50    50         0 -0.0798  0.0818 0.781      -0.647       0.488
##  4    50    50         0 -0.0589  0.102  0.854      -0.692       0.574
##  5    50    50         0  0.0251  0.118  0.942      -0.658       0.708
##  6    50    50         0 -0.115   0.106  0.725      -0.761       0.531
##  7    50    50         0  0.157   0.115  0.645      -0.517       0.831
##  8    50    50         0 -0.213   0.121  0.543      -0.903       0.478
##  9    50    50         0  0.509   0.117  0.139      -0.169       1.19 
## 10    50    50         0 -0.354   0.0774 0.206      -0.906       0.198
## # … with 7,990 more rows</code></pre>
</div>
</div>
<div id="absolute-vs.-relative-performance-measures" class="section level2 hasAnchor" number="7.8">
<h2><span class="header-section-number">7.8</span> Absolute vs. relative performance measures<a href="performance-criteria.html#absolute-vs.-relative-performance-measures" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Depending on the model and estimation procedures being examined, a range of different criteria might be used to assess estimator performance.
In particular, one might be deciding between using an absolute vs. relative performance measure.
How does one pick?</p>
<p>In the above, we presented the absolute criteria for the point estimators and relative criteria for standard error estimators.
But it turns out that this is not a fixed rule.</p>
<p>In general, we do not expect, for the performance (bias, variance, and MSE) of a point estimate such as a mean estimate to depend on its magnitude.
In other words, if we are estimating some mean <span class="math inline">\(\theta\)</span>, and we generate data where <span class="math inline">\(\theta = 100\)</span> vs <span class="math inline">\(\theta = 1000\)</span> (or any arbitrary number), we would not generally expect that to change the magnitude of its bias, variance, or MSE.
On the other hand, these different <span class="math inline">\(\theta\)</span>s will have a large impact on the <em>relative</em> bias and <em>relative</em> MSE.
(Want smaller relative bias? Just add a million to the parameter!)
For these sorts of “location parameters” we generally use absolute measures of performance.</p>
<p>That being said, a more principled approach for determining whether to use absolute or relative performance criteria depends on assessing performance for <em>multiple</em> values of the parameter. In many simulation studies, replications are generated and performance criteria are calculated for several different values of a parameter, say <span class="math inline">\(\theta = \theta_1,...,\theta_p\)</span>.
Let’s focus on bias for now, and say that we’ve estimated (from a large number of replications) the bias at each parameter value.</p>
<p><img src="Designing-Simulations-in-R_files/figure-html/unnamed-chunk-68-1.png" width="75%" style="display: block; margin: auto;" /></p>
<p>If the absolute bias is roughly the same for all values of <span class="math inline">\(\theta\)</span> (as in the plot on the left), then it makes sense to report absolute bias as the summary performance criterion. On the other hand, if the bias grows roughly in proportion to <span class="math inline">\(\theta\)</span> (as in the plot on the right), then relative bias is a better summary criterion.</p>
<p>More broadly, one can calculate performance relative to some baseline.
For example, if one of the estimators is the “generic method”, we could calculate ratios of the RMSE of our estimators to the baseline RMSE.
This can provide a way of standardizing across simulation scenarios where the overall scale of the RMSE changes radically.
While a powerful tool, it is not without risks: if you scale relative to something, then higher or lower ratios can either be due to the primary method of interest (the numerator) or behavior of the reference method in the denominator.
These relative ratios can end up being confusing to interpret due to this tension.</p>
</div>
<div id="exercises-simulating-cronbachs-alpha" class="section level2 hasAnchor" number="7.9">
<h2><span class="header-section-number">7.9</span> Exercises: Simulating Cronbach’s alpha<a href="performance-criteria.html#exercises-simulating-cronbachs-alpha" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Cronbach’s <span class="math inline">\(\alpha\)</span> coefficient is commonly reported as a measure of the internal consistency among a set of test items. Consider a set of <span class="math inline">\(p\)</span> test items with population variance-covariance matrix <span class="math inline">\(\boldsymbol\Phi = \left[\phi_{ij}\right]_{i,j=1}^p\)</span>.
This population variance-covariance matrix describes how our <span class="math inline">\(p\)</span> test items co-vary.</p>
<p>Cronback’s <span class="math inline">\(\alpha\)</span> is, under this model, defined as
<span class="math display">\[
\alpha = \frac{p}{p - 1}\left(1 - \frac{\sum_{i=1}^p \phi_{ii}}{\sum_{i=1}^p \sum_{j=1}^p \phi_{ij}}\right).
\]</span></p>
<p>Given a sample of size <span class="math inline">\(n\)</span>, the usual estimate of <span class="math inline">\(\alpha\)</span> is obtained by replacing the population variances and covariances with corresponding sample estimates. Letting <span class="math inline">\(s_{ij}\)</span> denote the sample covariance of items <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span></p>
<p><span class="math display">\[
A = \frac{p}{p - 1}\left(1 - \frac{\sum_{i=1}^p s_{ii}}{\sum_{i=1}^p \sum_{j=1}^p s_{ij}}\right).
\]</span></p>
<p>If we assume that the items follow a multivariate normal distribution, then <span class="math inline">\(A\)</span> corresponds to the maximum likelihood estimator of <span class="math inline">\(\alpha\)</span>.</p>
<p>In these exercises, we will examine the properties of this estimator when the set of <span class="math inline">\(P\)</span> items is <em>not</em> multi-variate normal, but rather follows a multivariate <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(v\)</span> degrees of freedom. For simplicity, we shall assume that the items have common variance and have a <strong>compound symmetric</strong> covariance matrix, such that <span class="math inline">\(\phi_{11} = \phi_{22} = \cdots = \phi_{pp} = \phi\)</span> and <span class="math inline">\(\phi_{ij} = \rho \phi\)</span>. In this case we can simplify our expression for <span class="math inline">\(\alpha\)</span> to</p>
<p><span class="math display">\[
\alpha = \frac{p \rho}{1 + \rho (p - 1)}.
\]</span></p>
<div id="the-data-generating-function" class="section level3 hasAnchor" number="7.9.1">
<h3><span class="header-section-number">7.9.1</span> The data-generating function<a href="performance-criteria.html#the-data-generating-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The following function generates a sample of <span class="math inline">\(n\)</span> observations of <span class="math inline">\(p\)</span> items from a multivariate t distribution with a compound symmetric covariance matrix, intra-class correlation <span class="math inline">\(\rho\)</span>, and <span class="math inline">\(v\)</span> degrees of freedom:</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="performance-criteria.html#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mvtnorm)</span>
<span id="cb139-2"><a href="performance-criteria.html#cb139-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-3"><a href="performance-criteria.html#cb139-3" aria-hidden="true" tabindex="-1"></a>r_mvt_items <span class="ot">&lt;-</span> <span class="cf">function</span>(n, p, icc, df) {</span>
<span id="cb139-4"><a href="performance-criteria.html#cb139-4" aria-hidden="true" tabindex="-1"></a>  V_mat <span class="ot">&lt;-</span> icc <span class="sc">+</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">-</span> icc, <span class="at">nrow =</span> p)</span>
<span id="cb139-5"><a href="performance-criteria.html#cb139-5" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">rmvt</span>(<span class="at">n =</span> n, <span class="at">sigma =</span> V_mat, <span class="at">df =</span> df)</span>
<span id="cb139-6"><a href="performance-criteria.html#cb139-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colnames</span>(X) <span class="ot">&lt;-</span> LETTERS[<span class="dv">1</span><span class="sc">:</span>p]</span>
<span id="cb139-7"><a href="performance-criteria.html#cb139-7" aria-hidden="true" tabindex="-1"></a>  X</span>
<span id="cb139-8"><a href="performance-criteria.html#cb139-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb139-9"><a href="performance-criteria.html#cb139-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-10"><a href="performance-criteria.html#cb139-10" aria-hidden="true" tabindex="-1"></a>small_sample <span class="ot">&lt;-</span> <span class="fu">r_mvt_items</span>(<span class="at">n =</span> <span class="dv">8</span>, <span class="at">p =</span> <span class="dv">3</span>, <span class="at">icc =</span> <span class="fl">0.7</span>, <span class="at">df =</span> <span class="dv">5</span>)</span>
<span id="cb139-11"><a href="performance-criteria.html#cb139-11" aria-hidden="true" tabindex="-1"></a>small_sample</span></code></pre></div>
<pre><code>##                A          B           C
## [1,]  0.09382233 -0.3954138 -0.07444013
## [2,] -0.26192949 -0.4419227 -0.39160382
## [3,]  0.39158338  0.9757591 -0.53170400
## [4,] -0.05918679 -1.5391954 -0.79945929
## [5,] -1.84261034  0.1107519 -1.08034605
## [6,]  0.39922138  0.3197069  0.59206764
## [7,] -0.19669418 -0.6172658 -1.43238613
## [8,] -0.75393141 -0.8665165  0.03773137</code></pre>
<p>To check that the function is indeed simulating data following the intended distribution, let’s generate a very large sample of items. We can then verify that the correlation matrix of the items is compound-symmetric and that the marginal distributions of the items follow t distributions with specified degrees of freedom.</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="performance-criteria.html#cb141-1" aria-hidden="true" tabindex="-1"></a>big_sample <span class="ot">&lt;-</span> <span class="fu">r_mvt_items</span>(<span class="at">n =</span> <span class="dv">100000</span>, <span class="at">p =</span> <span class="dv">4</span>, <span class="at">icc =</span> <span class="fl">0.7</span>, <span class="at">df =</span> <span class="dv">5</span>)</span>
<span id="cb141-2"><a href="performance-criteria.html#cb141-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb141-3"><a href="performance-criteria.html#cb141-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">cor</span>(big_sample), <span class="dv">3</span>) <span class="co"># looks good</span></span></code></pre></div>
<pre><code>##       A     B     C     D
## A 1.000 0.701 0.702 0.702
## B 0.701 1.000 0.700 0.703
## C 0.702 0.700 1.000 0.700
## D 0.702 0.703 0.700 1.000</code></pre>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="performance-criteria.html#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qqplot</span>(<span class="fu">qt</span>(<span class="fu">ppoints</span>(<span class="dv">200</span>), <span class="at">df =</span> <span class="dv">5</span>), big_sample[,<span class="dv">2</span>], <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>,<span class="dv">4</span>))</span></code></pre></div>
<p><img src="Designing-Simulations-in-R_files/figure-html/unnamed-chunk-70-1.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="the-estimation-function" class="section level3 hasAnchor" number="7.9.2">
<h3><span class="header-section-number">7.9.2</span> The estimation function<a href="performance-criteria.html#the-estimation-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>van Zyl, Neudecker, and Nel (2000) demonstrate that, if the items have a compound-symmetric covariance matrix, then the asymptotic variance of <span class="math inline">\(A\)</span> is
<span class="math display">\[
\text{Var}(A) \approx \frac{2p(1 - \alpha)^2}{(p - 1) n}.
\]</span>
Substituting <span class="math inline">\(A\)</span> in place of <span class="math inline">\(\alpha\)</span> gives an estimate of the variance of <span class="math inline">\(A\)</span>. The following function calculates <span class="math inline">\(A\)</span> and its variance estimator from a sample of data:</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="performance-criteria.html#cb144-1" aria-hidden="true" tabindex="-1"></a>estimate_alpha <span class="ot">&lt;-</span> <span class="cf">function</span>(dat) {</span>
<span id="cb144-2"><a href="performance-criteria.html#cb144-2" aria-hidden="true" tabindex="-1"></a>  V <span class="ot">&lt;-</span> <span class="fu">cov</span>(dat)</span>
<span id="cb144-3"><a href="performance-criteria.html#cb144-3" aria-hidden="true" tabindex="-1"></a>  p <span class="ot">&lt;-</span> <span class="fu">ncol</span>(dat)</span>
<span id="cb144-4"><a href="performance-criteria.html#cb144-4" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(dat)</span>
<span id="cb144-5"><a href="performance-criteria.html#cb144-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb144-6"><a href="performance-criteria.html#cb144-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate A with our formula</span></span>
<span id="cb144-7"><a href="performance-criteria.html#cb144-7" aria-hidden="true" tabindex="-1"></a>  A <span class="ot">&lt;-</span> p <span class="sc">/</span> (p <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">sum</span>(<span class="fu">diag</span>(V)) <span class="sc">/</span> <span class="fu">sum</span>(V))</span>
<span id="cb144-8"><a href="performance-criteria.html#cb144-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb144-9"><a href="performance-criteria.html#cb144-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate our estimate of the variance (SE^2) of A</span></span>
<span id="cb144-10"><a href="performance-criteria.html#cb144-10" aria-hidden="true" tabindex="-1"></a>  Var_A <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> p <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> A)<span class="sc">^</span><span class="dv">2</span> <span class="sc">/</span> ((p <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> n)</span>
<span id="cb144-11"><a href="performance-criteria.html#cb144-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb144-12"><a href="performance-criteria.html#cb144-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Pack up our results</span></span>
<span id="cb144-13"><a href="performance-criteria.html#cb144-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">A =</span> A, <span class="at">Var =</span> Var_A)</span>
<span id="cb144-14"><a href="performance-criteria.html#cb144-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb144-15"><a href="performance-criteria.html#cb144-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb144-16"><a href="performance-criteria.html#cb144-16" aria-hidden="true" tabindex="-1"></a><span class="fu">estimate_alpha</span>(small_sample)</span></code></pre></div>
<pre><code>##           A        Var
## 1 0.4922233 0.09668892</code></pre>
<p>The <code>psych</code> package provides a function for calculating <span class="math inline">\(\alpha\)</span>, which can be used to verify that the calculation of <span class="math inline">\(A\)</span> in <code>estimate_alpha</code> is correct:</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="performance-criteria.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;psych&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:ggplot2&#39;:
## 
##     %+%, alpha</code></pre>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="performance-criteria.html#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">alpha</span>(<span class="at">x =</span> small_sample))<span class="sc">$</span>raw_alpha</span></code></pre></div>
<pre><code>## Number of categories should be increased  in order to count frequencies.</code></pre>
<pre><code>## 
## Reliability analysis   
##  raw_alpha std.alpha G6(smc) average_r S/N  ase  mean   sd median_r
##       0.49       0.5    0.43      0.25   1 0.32 -0.35 0.51      0.2</code></pre>
<pre><code>## NULL</code></pre>
</div>
<div id="replicates" class="section level3 hasAnchor" number="7.9.3">
<h3><span class="header-section-number">7.9.3</span> Replicates<a href="performance-criteria.html#replicates" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The following function generates a specified number of replicates of <span class="math inline">\(A\)</span> and its variance estimator, for user-specified parameter values <span class="math inline">\(n\)</span>, <span class="math inline">\(p\)</span>, <span class="math inline">\(\alpha\)</span>, and <span class="math inline">\(v\)</span>:</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="performance-criteria.html#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb153-2"><a href="performance-criteria.html#cb153-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb153-3"><a href="performance-criteria.html#cb153-3" aria-hidden="true" tabindex="-1"></a>simulate_alpha <span class="ot">&lt;-</span> <span class="cf">function</span>(reps, n, p, alpha, df) {</span>
<span id="cb153-4"><a href="performance-criteria.html#cb153-4" aria-hidden="true" tabindex="-1"></a>  icc <span class="ot">&lt;-</span> alpha <span class="sc">/</span> (p <span class="sc">-</span> alpha <span class="sc">*</span> (p <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb153-5"><a href="performance-criteria.html#cb153-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">replicate</span>(reps, {</span>
<span id="cb153-6"><a href="performance-criteria.html#cb153-6" aria-hidden="true" tabindex="-1"></a>    dat <span class="ot">&lt;-</span> <span class="fu">r_mvt_items</span>(<span class="at">n =</span> n, <span class="at">p =</span> p, <span class="at">icc =</span> icc, <span class="at">df =</span> df)</span>
<span id="cb153-7"><a href="performance-criteria.html#cb153-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">estimate_alpha</span>(dat)</span>
<span id="cb153-8"><a href="performance-criteria.html#cb153-8" aria-hidden="true" tabindex="-1"></a>  }, <span class="at">simplify =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb153-9"><a href="performance-criteria.html#cb153-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>()</span>
<span id="cb153-10"><a href="performance-criteria.html#cb153-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We can use it to generate 1000 replicates using samples of size <span class="math inline">\(n = 40\)</span>, <span class="math inline">\(p = 6\)</span> items, a true <span class="math inline">\(\alpha = 0.8\)</span>, and <span class="math inline">\(v = 5\)</span> degrees of freedom:</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="performance-criteria.html#cb154-1" aria-hidden="true" tabindex="-1"></a>reps <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb154-2"><a href="performance-criteria.html#cb154-2" aria-hidden="true" tabindex="-1"></a>alpha_true <span class="ot">&lt;-</span> <span class="fl">0.8</span></span>
<span id="cb154-3"><a href="performance-criteria.html#cb154-3" aria-hidden="true" tabindex="-1"></a>alpha_reps <span class="ot">&lt;-</span> <span class="fu">simulate_alpha</span>(<span class="at">reps =</span> reps, <span class="at">n =</span> <span class="dv">40</span>, <span class="at">p =</span> <span class="dv">6</span>, <span class="at">alpha =</span> alpha_true, <span class="at">df =</span> <span class="dv">5</span>)</span>
<span id="cb154-4"><a href="performance-criteria.html#cb154-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(alpha_reps)</span></code></pre></div>
<pre><code>##           A         Var
## 1 0.8030085 0.002328340
## 2 0.8023319 0.002344362
## 3 0.8328883 0.001675579
## 4 0.7354949 0.004197777
## 5 0.6870548 0.005876084
## 6 0.7876845 0.002704671</code></pre>
</div>
<div id="estimator-performance" class="section level3 hasAnchor" number="7.9.4">
<h3><span class="header-section-number">7.9.4</span> Estimator performance<a href="performance-criteria.html#estimator-performance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>With the parameters specified above, calculate the bias of <span class="math inline">\(A\)</span>. Also calculate the Monte Carlo standard error (MCSE) of the bias estimate.</p></li>
<li><p>Calculate the mean squared error of <span class="math inline">\(A\)</span>, along with its MCSE.</p></li>
<li><p>Calculate the relative bias of the asymptotic variance estimator.</p></li>
<li><p><strong>(Challenge problem)</strong> Code up a jackknife MCSE function to calculate the MCSE for the relative bias of the asymptotic variance estimator. Let it use the following template that takes a vector of point estimates and associated standard errors.</p></li>
</ol>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="performance-criteria.html#cb156-1" aria-hidden="true" tabindex="-1"></a>jackknife_MCSE <span class="ot">&lt;-</span> <span class="cf">function</span>( T, SE ) {</span>
<span id="cb156-2"><a href="performance-criteria.html#cb156-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># code</span></span>
<span id="cb156-3"><a href="performance-criteria.html#cb156-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<ol start="5" style="list-style-type: decimal">
<li><strong>(Challenge problem)</strong> Make a <code>run_simulation()</code> function that uses <code>simulate_alpha</code> and returns a one-row data frame with columns corresponding to the bias, mean squared error, and relative bias of the asymptotic variance estimator. Use the function to evaluate the performance of <span class="math inline">\(A\)</span> for true values of <span class="math inline">\(\alpha\)</span> ranging from 0.5 to 0.9 (i.e., <code>alpha_true_seq &lt;- seq(0.5, 0.9, 0.1)</code>).</li>
</ol>
</div>
<div id="confidence-interval-coverage" class="section level3 hasAnchor" number="7.9.5">
<h3><span class="header-section-number">7.9.5</span> Confidence interval coverage<a href="performance-criteria.html#confidence-interval-coverage" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One way to obtain an approximate confidence interval for <span class="math inline">\(\alpha\)</span> would be to take <span class="math inline">\(A \pm z \sqrt{\text{Var}(A)}\)</span>, where <span class="math inline">\(\text{Var}(A)\)</span> is estimated as described above and <span class="math inline">\(z\)</span> is a standard normal critical value at the appropriate level (i.e., <span class="math inline">\(z = 1.96\)</span> for a 95% CI). However, van Zyl, Neudecker, and Nel (2000) suggest that a better approximation involves first applying a transformation to <span class="math inline">\(A\)</span> (to make it more normal in shape), then calculating a confidence interval, then back-transforming to the original scale (this is very similar to the procedure for calculating confidence intervals for correlation coefficients, using Fisher’s <span class="math inline">\(z\)</span> transformation). Let</p>
<p><span class="math display">\[
\begin{aligned}
\beta &amp;= \frac{1}{2} \ln\left(1 - \alpha\right) \\
B &amp;= \frac{1}{2} \ln\left(1 - A\right)
\end{aligned}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
V^B = \frac{p}{2 n (p - 1)}.
\]</span></p>
<p>An approximate confidence interval for <span class="math inline">\(\beta\)</span> is given by <span class="math inline">\([B_L, B_U]\)</span>, where</p>
<p><span class="math display">\[
B_L = B - z \sqrt{V^B}, \qquad B_U = B + z \sqrt{V^B}.
\]</span></p>
<p>Applying the inverse of the transformation gives a confidence interval for <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[
\left[1 - \exp(2B_U), \ 1 - \exp(2 B_L)\right].
\]</span></p>
<ol start="6" style="list-style-type: decimal">
<li><p>Modify the <code>estimate_alpha</code> function to calculate a confidence interval for <span class="math inline">\(\alpha\)</span>, following the method described above.</p></li>
<li><p>With the modified version of <code>estimate_alpha</code>, re-run the following code to obtain 1000 replicated confidence intervals. Calculate the true coverage rate of the confidence interval. Also calculate the Monte Carlo standard error (MCSE) of this coverage rate.</p></li>
</ol>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="performance-criteria.html#cb157-1" aria-hidden="true" tabindex="-1"></a>reps <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb157-2"><a href="performance-criteria.html#cb157-2" aria-hidden="true" tabindex="-1"></a>alpha_true <span class="ot">&lt;-</span> <span class="fl">0.8</span></span>
<span id="cb157-3"><a href="performance-criteria.html#cb157-3" aria-hidden="true" tabindex="-1"></a>alpha_reps <span class="ot">&lt;-</span> <span class="fu">simulate_alpha</span>(<span class="at">reps =</span> reps, <span class="at">n =</span> <span class="dv">40</span>, <span class="at">p =</span> <span class="dv">6</span>, <span class="at">alpha =</span> alpha_true, <span class="at">df =</span> <span class="dv">5</span>)</span></code></pre></div>
<ol start="8" style="list-style-type: decimal">
<li><p>Calculate the average length of the confidence interval for <span class="math inline">\(\alpha\)</span>, along with its MCSE.</p></li>
<li><p>Compare the results of this approach to a more naive approach. Are there gains in performance?</p></li>
</ol>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimation-procedures.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="case_Cronbach.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/040-Performance-criteria.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Designing-Simulations-in-R.pdf", "Designing-Simulations-in-R.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
