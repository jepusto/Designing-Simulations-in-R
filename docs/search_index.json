[["running-the-simulation-process.html", "Chapter 8 Running the Simulation Process 8.1 Repeating oneself 8.2 One run at a time 8.3 Bundling simulations with {simhelpers} 8.4 Adding Checks and Balances 8.5 Seeds and pseudo-random number generators 8.6 Exercises", " Chapter 8 Running the Simulation Process In the prior two chapters we saw how to write functions that generate data according to a particular model (and user-specified input parameters) and functions that implement data-analysis or estimation procedures on the simulated data. The next step in a simulation involves putting these two pieces together, running the DGP function and the data-analysis function repeatedly to obtain results (in the form of point estimates, standard errors, confidence intervals, p-values, or other quantities) from many replications of the whole process. As with most things R-related, there are many different techniques that can be used to repeat a set of calculations over and over. In this chapter, we will demonstrate several techniques for doing so. We will then discuss how ensure reproducibility of simulation results by setting the seed used by R’s random number generator. 8.1 Repeating oneself Suppose that we want to simulate Pearson’s correlation coefficient calculated based on a sample from the bivariate Poisson function. We saw a DGP function for the bivariate Poisson in Section 6.3, and an estimation function in Section 7.1. To produce a simulated correlation coefficient, we need to run these two functions in turn: dat &lt;- r_bivariate_Poisson( N = 30, rho = 0.4, mu1 = 8, mu2 = 14 ) r_and_z(dat) ## # A tibble: 1 × 4 ## r z CI_lo CI_hi ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.537 0.600 0.219 0.752 To execute a simulation, we need to repeat this process over and over. R has many different functions for doing exactly this. The {simhelpers} package includes a function called repeat_and_stack(), which can be used to evaluate an arbitrary expression many times over. We can use it to generate five replications of our correlation coefficient: library(simhelpers) repeat_and_stack( n = 5, { dat &lt;- r_bivariate_Poisson( N = 30, rho = 0.4, mu1 = 8, mu2 = 14 ) r_and_z(dat) }, id = &quot;rep&quot;, stack = TRUE ) ## r z CI_lo CI_hi rep ## 1 0.2991630 0.3086000 -0.06848782 0.5952740 1 ## 2 0.1463949 0.1474544 -0.22578243 0.4812806 2 ## 3 0.4332997 0.4639520 0.08653974 0.6864162 3 ## 4 0.5129456 0.5667190 0.18728669 0.7370155 4 ## 5 0.3133391 0.3242438 -0.05290200 0.6052804 5 The first argument specifies the number of times to repeat the calculation. The second argument is an R expression that will be evaluated. The expression is wrapped in curly braces ({}) because it involves more than a single line of code. Including the option id = \"rep\" will return a dataset that includes a variable called rep to identify each replication of the process. Setting the option stack = TRUE will stack up the output of each expression into a single tibble, which will facilitate later calculations on the results. Setting this option is not necessary because it is TRUE by default; setting stack = FALSE will return the results in a list rather than a tibble (try this for yourself to see!). There are many other functions that work very much like repeat_and_stack(), including the base-R function replicate() and the now-deprecated function rerun() from {purrr}. The functions in the map() family from {purrr} can also be used to do the same thing as repeat_and_stack(). See Appendix 8.1 for more discussion of these alternatives. 8.2 One run at a time A slightly different technique for running multiple replications of a process is to first write a function that executes a single run of the simulation, and then repeatedly evaluate that a function. For instance, here is a function that stitching the two steps in the bivariate-Poisson correlation simulation: one_bivariate_Poisson_r &lt;- function(N, rho, mu1, mu2) { dat &lt;- r_bivariate_Poisson( N = N, rho = rho, mu1 = mu1, mu2 = mu2 ) res &lt;- r_and_z(dat) return(res) } Calling the function produces a nicely formatted set of results that we can then evaluate: one_bivariate_Poisson_r(N = 30, rho = 0.4, mu1 = 8, mu2 = 14) ## # A tibble: 1 × 4 ## r z CI_lo CI_hi ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.574 0.653 0.269 0.774 We can then evaluate the function over and over using repeat_and_stack(): repeat_and_stack( n = 5, one_bivariate_Poisson_r( N = 30, rho = 0.4, mu1 = 8, mu2 = 14 ), id = &quot;rep&quot; ) ## r z CI_lo CI_hi rep ## 1 0.4427140 0.4756013 0.09808968 0.6925277 1 ## 2 0.1683258 0.1699431 -0.20433485 0.4983724 2 ## 3 0.5192663 0.5753346 0.19558651 0.7409262 3 ## 4 0.5846490 0.6694971 0.28425204 0.7805171 4 ## 5 0.4655435 0.5043655 0.12648914 0.7072004 5 This technique of wrapping the data-generating function and estimation function inside of another function might strike you as a bit cumbersome because the wrapper is only two lines of code. Further, writing the wrapper requires repeating many of the function argument names when calling the data-generating function (N = N, rho = rho, etc.). However, the wrapper technique can be useful for more complicated simulations, such as those that involve comparison of multiple estimation methods. Consider the cluster-randomized experiment case study presented in Section 6.6 and 7.2. In this simulation, we are interested in comparing the performance of three different estimation methods: a multi-level model, a linear regression with clustered standard errors, and a linear regression on the data aggregated to the school level. Thus, we need to generate a dataset and then apply three different estimation functions to it. Here is a function that takes our simulation parameters and runs a single trial of the full process: one_run &lt;- function( n_bar = 30, J = 20, gamma_1 = 0.3, gamma_2 = 0.5, sigma2_u = 0.20, sigma2_e = 0.80, alpha = 0.75 ) { dat &lt;- gen_cluster_RCT( n_bar = n_bar, J = J, gamma_1 = gamma_1, gamma_2 = gamma_2, sigma2_u = sigma2_u, sigma2_e = sigma2_e, alpha = alpha ) MLM = analysis_MLM( dat ) LR = analysis_OLS( dat ) Agg = analysis_agg( dat ) bind_rows( MLM = MLM, LR = LR, Agg = Agg, .id = &quot;method&quot; ) } We have added a bunch of defaults to our function, so that we can run it without having to remember all the various input parameters. When we call the function, we get a nice table of results that we can evaluate: one_run( n_bar = 30, J = 20, alpha=0.5 ) ## # A tibble: 3 × 4 ## method ATE_hat SE_hat p_value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MLM 0.544 0.227 0.0280 ## 2 LR 0.576 0.222 0.0192 ## 3 Agg 0.533 0.229 0.0316 The results for each method are organized in separate lines. For each method, we record the impact estimate, its (estimated) standard error, and a nominal \\(p\\)-value. Note how the bind_rows() method can take naming on the fly, and give us a column of method, which will be very useful for keeping track of which results come from which estimation. We intentionally wrap up our results with a tibble to make later it easier to do subsequent data processing and analysis. Once we have a function to execute a single run of the simulation, we can produce multiple results using repeat_and_stack(): R &lt;- 1000 ATE &lt;- 0.30 runs &lt;- repeat_and_stack(R, one_run( n_bar = 30, J=20, gamma_1 = ATE ), id = &quot;runID&quot;) saveRDS( runs, file = &quot;results/cluster_RCT_simulation.rds&quot; ) Setting id = \"runID\" argument is a way of keeping track of which iteration number produced which result. Once our simulation is complete, we save our results to a file for future use. Doing so allows us to avoid having to re-run our simulation each time we want to explore the results. We now have results for each of our estimation methods applied to each of 1000 generated datasets. The next step is to evaluate how well the estimators did. Regarding the point estimates, for example, we will examine questions about bias, precision, and accuracy. In Chapter 9, we look systematically at ways to quantify the performance of estimation methods. 8.3 Bundling simulations with {simhelpers} The techniques that we have demonstrated for repeating a set of calculations over and over involve The map approach is a bit strange, with building a secret function on the fly with ~, and also having the copy over all the parameters we pass from one_run() to gen_cluster_RCT(). The simhelpers package provides a shortcut that makes this step easier. To do it, we first need to write a single estimation procedure function that puts all of our estimators together: analyze_data = function( dat ) { MLM = analysis_MLM( dat ) LR = analysis_OLS( dat ) Agg = analysis_agg( dat ) bind_rows( MLM = MLM, LR = LR, Agg = Agg, .id = &quot;method&quot; ) } This is simply the one_run() method from above, but without the data generating part. When we pass a dataset to it, we get a nice table of results that we can evaluate, as we did before. dat = gen_cluster_RCT( n=30, J = 20, gamma_1 = 0.30 ) analyze_data( dat ) ## # A tibble: 3 × 4 ## method ATE_hat SE_hat p_value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MLM 0.239 0.165 0.168 ## 2 LR 0.230 0.190 0.249 ## 3 Agg 0.170 0.274 0.542 We can now use simhelpers to write us a new function for the entire simulation: library(simhelpers) sim_function &lt;- bundle_sim( gen_cluster_RCT, analyze_data ) We can then use it as so: sim_function( 2, n_bar = 30, J = 20, gamma_1 = ATE ) ## boundary (singular) fit: see help(&#39;isSingular&#39;) ## # A tibble: 6 × 4 ## method ATE_hat SE_hat p_value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MLM 0.188 0.150 0.227 ## 2 LR 0.202 0.154 0.213 ## 3 Agg 0.217 0.159 0.189 ## 4 MLM 0.243 0.124 0.0508 ## 5 LR 0.243 0.0876 0.0167 ## 6 Agg 0.404 0.122 0.00392 The bundle_sim() command takes our DGP function and our estimation procedures function and gives us back a function, which we have called sim_function, that will run a simulation using whatever parameters we give it. The bundle_sim() command examines gen_cluster_RCT function, figures out what parameters it needs, and makes sure that the newly created function is able to take those parameters from the user. To use it for our simulation, we would then write rns &lt;- sim_function( R, n_bar = 30, J = 20, gamma_1 = ATE ) saveRDS( runs, file = &quot;results/cluster_RCT_simulation.rds&quot; ) This is a bit more elegant than the map() approach, and is especially useful when we have a lot of parameters to pass around. 8.4 Adding Checks and Balances In the extensions of the prior DGP chapter, we discussed indexing our DGP by the ICC instead of the two variance components. We can do this, and also translate some of the more obscure model parameters to easier to interpret parameters from within our simulation driver as follows: one_run &lt;- function( n_bar = 30, J=20, ATE = 0.3, size_coef = 0.5, ICC = 0.4, alpha = 0.75 ) { stopifnot( ICC &gt;= 0 &amp;&amp; ICC &lt; 1 ) dat &lt;- gen_cluster_RCT( n_bar = n_bar, J=J, gamma_1 = ATE, gamma_2 = size_coef, sigma2_u = ICC, sigma2_e = 1-ICC, alpha = alpha ) MLM = analysis_MLM( dat ) LR = analysis_OLS( dat ) Agg = analysis_agg( dat ) bind_rows( MLM = MLM, LR = LR, Agg = Agg, .id = &quot;method&quot; ) } Note the stopifnot: it is wise to ensure our parameter transforms are all reasonable, so we do not get unexplained errors or strange results later on. It is best if your code fails as soon as possible! Otherwise debugging can be quite hard. In our modified one_run() we are transforming our ICC parameter into specific other parameters that are used in our actual model to maintain our effect size interpretation of our simulation. We have not even modified our gen_cluster_RCT() DGP method: we are just specifying the constellation of parameters as a function of the parameters we want to directly control in the simulation. Controlling how we use the foundational elements such as our data generating code is a key tool for making the higher level simulations sensible and more easily interpretable. Here we have put our entire simulation into effect size units, and are now providing “knobs” to the simulation that are directly interpretable. 8.5 Seeds and pseudo-random number generators In prior chapters, we have used built-in functions to generate random numbers and also written our own data-generating functions that produce artificial data following a specific random process. With either type of function, re-running it with the exact same input parameters will produce different results. For instance, running the rchisq function with the same set of inputs will produce two different sequences of \\(\\chi^2\\) random variables: c1 &lt;- rchisq(4, df = 3) c2 &lt;- rchisq(4, df = 3) rbind(c1, c2) ## [,1] [,2] [,3] [,4] ## c1 0.6386982 4.1204725 4.915787 2.273877 ## c2 0.6499199 0.2419481 2.452350 1.363941 Likewise, running the bivariate Poisson function from Section 6.3 twice will produce different datasets: dat_A &lt;- r_bivariate_Poisson(20, rho = 0.5, mu1 = 4, mu2 = 7) dat_B &lt;- r_bivariate_Poisson(20, rho = 0.5, mu1 = 4, mu2 = 7) identical(dat_A, dat_B) ## [1] FALSE bind_rows(A = r_and_z(dat_A), B = r_and_z(dat_B), .id = &quot;Rep&quot;) ## # A tibble: 2 × 5 ## Rep r z CI_lo CI_hi ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 0.705 0.877 0.382 0.875 ## 2 B 0.277 0.284 -0.189 0.641 Of course, this is the intended behavior of the function. However, if you run the same code as above, you will get different results. Thus, using functions like rchisq() or r_bivariate_Poisson() in a simulation study means that our results will not be entirely reproducible. When using DGP functions for simulations, it is useful to be able to exactly control the process of generating random numbers. This is more possible than it sounds: Monte Carlo simulations are random, at least in theory, but computers are deterministic. When we use R to generate what we have been referring to as “random numbers,” the functions produce what are actually pseudo-random numbers. Pseudo-random numbers are generated from chains of mathematical equations designed to produce sequences of numbers that appear random, but actually follow a deterministic sequence. Each subsequent random number is a calculated by starting from the previously generated value (i.e., the current state of the random number generator), applying a complicated function, and storing the result (i.e., updating the state). The numbers returned by the generator form a chain that, ideally, cycles through an extremely long list of values in way that looks stochastic and unpredictable. The state of the generator is shared across different functions that produce pseudo-random numbers, so it does not matter if we are generating numbers with rnorm() or rchisq() or r_bivariate_Poisson(). Each time we ask for a random number from the generator, its state is updated. Functions like rnorm() and rchisq() all call the low-level generator and then transform the result to be of the correct distribution. Because the generator is actually deterministic, we can control its output by specify a starting value or initial state, In R, the state of the random number generator can be controlled by setting what its known as the seed. The set.seed() function allows us to specify a seed value, so that we can exactly reproduce a calculation. For example, set.seed(6) c1 &lt;- rchisq(4, df = 3) set.seed(6) c2 &lt;- rchisq(4, df = 3) rbind(c1, c2) ## [,1] [,2] [,3] [,4] ## c1 2.575556 0.93847 8.062264 3.685932 ## c2 2.575556 0.93847 8.062264 3.685932 Similarly, we can set the seed and run a series of calculations involving multiple functions that make use of the random number generator: # First time set.seed(6) c1 &lt;- rchisq(4, df = 3) dat_A &lt;- r_bivariate_Poisson(20, rho = 0.5, mu1 = 4, mu2 = 7) # Exactly reproduce the calculations set.seed(6) c2 &lt;- rchisq(4, df = 3) dat_B &lt;- r_bivariate_Poisson(20, rho = 0.5, mu1 = 4, mu2 = 7) bind_rows(A = r_and_z(dat_A), B = r_and_z(dat_B), .id = &quot;Rep&quot;) ## # A tibble: 2 × 5 ## Rep r z CI_lo CI_hi ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 A 0.299 0.308 -0.165 0.655 ## 2 B 0.299 0.308 -0.165 0.655 In practice, it is a good idea to always set seed values for your simulations, so that you (or someone else!) can exactly reproduce the results. Attending to reproducibility allows us to easily check if we are running the same code that generated a set of results. For instance, try running the previous block of code on your machine; if you set the seed to the same value as we did, you should get identical output. Setting seeds is also very helpful for debugging. For example, say we had an error that showed up one in a thousand, causing our simulation to crash sometimes. If we set a seed and see that it crashes, we can repair our code and then rerun the simulation. If it runs without error, we know we fixed the problem. If we had not set the seed, we would not know if we were just getting (un)lucky, and avoiding the error by chance. 8.6 Exercises In the prior chapter’s exercises, you made a new BF_F function for the Welch simulation. Now incorporate the BF_F function into the one_run() function, and use your revised function to generate simulation results for this additional estimator. "]]
