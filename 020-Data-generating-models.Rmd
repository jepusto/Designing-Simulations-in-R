```{r echo = FALSE, messages = FALSE, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, 
                      fig.width = 5,
                      fig.height = 3,
                      out.width = "75%", 
                      fig.align = "center")
options(list(dplyr.summarise.inform = FALSE))
theme_set( theme_classic() )

```


# Data-generating models {#chap_DGP}

The data generating model, or data generating process (DGP), is the recipe we use to create fake data that we will use for analysis.
When we generate from a specified model we know what the "right answer" is.
We can then compare our estimates to this right answer, to assess whether our estimation procedures worked.

The easiest way to describe a DGP is usually via a sequence of equations and random variables that define a series of steps.
These will, in the end, be a function of a set of parameters, values that we must specify.
We then convert these equations to code by following the steps laid out.

For example, for the Welch data earlier we have, for observation $i$ in group $g$, a mathematical representation of our data of:

$$ X_{ig} = \mu_g + \epsilon_{ig} \mbox{ with } \epsilon_{ig} \sim N( 0, \sigma^2_g ) $$
These math equations would also come along with specified parameter values (the $\mu_g$, etc), and sample size requirements.

In terms of code, a function that implements a data-generating model should have the following form:
```{r}
generate_data <- function(parameters) {

  # generate pseudo-random numbers and use those to
  # make some data
  
  return(sim_data)
}
```

The function takes a set of parameter values as input, simulates random numbers and does calculations, and produces as output a set of simulated data.
Again, there will in general be multiple parameters, and these will include not only the model parameters (e.g. the coefficients of a regression), but also sample sizes and other study design parameters.
The output will typically be a dataframe, mimicking what data one would see in the "real world," possibly augmented by some other latent values that we can use later on to assess whether the estimation procedures we are checking are close to the truth.

For example, from our Welch case study, we have the following method that generates grouped data with a single outcome.

```{r}
generate_data <- function(mu, sigma_sq, sample_size) {

  N <- sum(sample_size) 
  g <- length(sample_size) 
  
  group <- rep(1:g, times = sample_size) 
  mu_long <- rep(mu, times = sample_size)
  sigma_long <- rep(sqrt(sigma_sq), times = sample_size) 
  
  x <- rnorm(N, mean = mu_long, sd = sigma_long)
  sim_data <- tibble(group = group, x = x)
    
  return(sim_data)
}
```

Our function takes parameters as we normally thing of them (`mu`, `sigma_sq`), and other values that we might not think of as parameters per-se (`sample_size`).
When simulating data, we have to specify quantities that we, when analyzing data, often have to take for granted.

We our method as so:
```{r}
mu <- c(1, 2, 5, 6)
sigma_sq <- c(3, 2, 5, 1)
sample_size <- c(3, 6, 2, 4)

sim_dat <- generate_data(mu = mu, 
                         sigma_sq = sigma_sq, 
                         sample_size = sample_size)
sim_dat
```





## Checking the data-generating function

An important part of programing in R---particularly writing functions---is finding ways to test and check the correctness of your code. Thus, after writing a data-generating function, we need to consider how to test whether the output it produces is correct. How best to do this will depend on the data-generating model being implemented. 

For the heteroskedastic ANOVA problem, one basic thing we could do is check that the simulated data from each group follows a normal distribution. By generating very large samples from each group, we can effectively check characteristics of the population distribution.
In the following code, we simulate very large samples from each of the four groups, and check that the means and variances agree with the input parameters:

```{r, fig.width = 4, fig.height = 4, fig.show = "hold"}
check_data <- generate_data(mu = mu, sigma_sq = sigma_sq,
                            sample_size = rep(10000, 4))

chk <- check_data %>% group_by( group ) %>%
  dplyr::summarise( n = n(),
             mean = mean( x ),
             var = var( x ) ) %>%
  mutate( mu = mu,
          sigma2 = sigma_sq ) %>%
  relocate( group, n, mean, mu, var, sigma2 )
chk
```

We are recovering our parameters.

We can also make some diagnostic plots to assess whether we have normal data (using QQ plots, where we expect a straight line if the data are normal):
```{r}
ggplot( check_data, aes( sample=x ) ) +
  facet_wrap( ~ group ) +
  stat_qq()
```




## Exercises (the Shifted-and-scaled t distribution) {#ex_dgp}

The shifted-and-scaled $t$-distribution has parameters $\mu$ (mean), $\sigma$ (scale), and $\nu$ (degrees of freedom).
If $T$ follows a student's $t$-distribution with $\nu$ degrees of freedom, then $S = \mu + \sigma T$ follows a shifted-and-scaled $t$-distribution.

The following function will generate random draws from this distribution (the scaling of $(\nu-2)/\nu$ is to account for a non-scaled $t$-distribution having a variance of $\nu/(\nu-2)$).

```{r}
r_tss <- function(n, mean, sd, df) {
  mean + sd * sqrt( (df-2)/df ) * rt(n = n, df = df)
}

r_tss(n = 8, mean = 3, sd = 2, df = 5)
```

1. Modify the above `simulate_data` function to generate data from shifted-and-scaled $t$-distributions rather than from normal distributions. Include the degrees of freedom as an input argument.
Simulate a dataset with low degrees of freedom and plot it to see if you see a few outliers.

2. Now generate more data and calculate the standard deviations to see if they are correctly calibrated (generate a big dataset to ensure you get a reliable standard deviation estimate).

3. Once you are satisfied you have a correct DGP function, re-run the Type-I error rate calculations from the prior exercises [link](#exAnovaExercises) on page @exAnovaExercises using a $t$-distribution with 5 degrees of freedom.
Do the results change substantially?

